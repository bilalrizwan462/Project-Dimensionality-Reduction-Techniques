{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e6c9a4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Comparison of Dimensionality Reduction Techniques on Machine Learning\n",
    "\n",
    "###                                                              By: Syed Bilal Rizwan\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75afa8e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1. Aim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238397f4",
   "metadata": {},
   "source": [
    "The aim of this project is to compare different dimensionality reduction techniques and their effect on Machine Learning performance. The techniques are tried on 15 datasets to see the general behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf5fd03",
   "metadata": {},
   "source": [
    "# 2. Datasets Chosen\n",
    "\n",
    "## 2.1 Classification Datasets Description:\n",
    "\n",
    "   1. **Marketing Campaign Dataset**: A response model can provide a significant boost to the efficiency of a marketing campaign by increasing responses or reducing expenses. The objective is to predict who will respond to an offer for a product or  service.\n",
    "    \n",
    "   2. **Credit Card Fraud Dataset**: The dataset contains transactions made by credit cards in September 2013 by European cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "    \n",
    "   3. **Heart Disease Prediction Dataset**: According to the CDC, heart disease is one of the leading causes of death for people of most races in the US (African Americans, American Indians and Alaska Natives, and white people). Originally, the dataset come from the CDC and is a major part of the Behavioral Risk Factor Surveillance System (BRFSS), which conducts annual telephone surveys to gather data on the health status of U.S. residents. It consists of 401,958 rows and 279 columns which are reduced to 20 columns. \n",
    "    \n",
    "   4. **Diabetes Dataset**: The dataset represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. It includes over 50 features representing patient and hospital outcomes. \n",
    "    \n",
    "   5. **High Income Prediction**: Extraction was done by Barry Becker from the 1994 Census database. A set of clean records was extracted. Prediction task is to determine whether a person makes over 50K a year.\n",
    "    \n",
    "   6. **Dry Beans Dataset**: Images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. A total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains. Prediction task is to find out the type of bean it is.\n",
    "    \n",
    "   7. **Banknote Authentication Dataset**: Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels.\n",
    "    \n",
    "   8. **Audit Data**: The goal of the research is to help the auditors by building a classification model that can predict the fraudulent firm on the basis the present and historical risk factors.\n",
    "    \n",
    "## 2.2 Regression Dataset Description:\n",
    "\n",
    "   1. **Combined Cycle Power Plant Dataset**: The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP) of the plant. Prediction task is to predict the Electrical Energy Output.\n",
    "    \n",
    "   2. **Energy Efficiency Dataset**: Perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. \n",
    "    \n",
    "   3. **QSAR Aquatic Toxicity Dataset**: This dataset was used to develop quantitative regression QSAR models to predict acute aquatic toxicity towards the fish Pimephales promelas (fathead minnow) on a set of 908 chemicals. to predict acute aquatic toxicity towards Daphnia Magna. LC50 data, which is the concentration that causes death in 50% of test D. magna over a test duration of 48 hours, was used as model response.\n",
    "    \n",
    "   4. **Bike Sharing Dataset**: Bike sharing systems are new generation of traditional bike rentals where entire process from membership, rental and return has become automatic. Through these systems, user can easily rent a bike from a particular position and return at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousand bicycles. Today, there exists great interest in these systems due to their key role in traffic, environmental and health issues. Goal is to predict the number of bikes given the other variables.\n",
    "    \n",
    "   5. **Wine Quality Dataset**: Goal is to predict the quality of wine given the other variables.\n",
    "    \n",
    "   6. **Student Performance Dataset**: This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. \n",
    "    \n",
    "   7. **Buzz in social media(Tom's Hardware Dataset)**: This dataset contains examples of buzz events from two different social networks: Twitter, and Tom's Hardware, a forum network focusing on modern technology with more conservative dynamics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d64a8",
   "metadata": {},
   "source": [
    "# 3. Background\n",
    "\n",
    "Training a machine learning model on large datasets require a lot of computational resources and is excessively time consuming as well. To achieve the end-goal in a realistic timeframe, it is important to think of ways to pre-process dataset in a way which leads to less computation and allow scalability. This is where dimensionality reduction techniques come into the picture.\n",
    "\n",
    "Dimensionality reduction maps a high dimensional dataset into a lower dimensional space without losing information in the dataset. These techniques are used as a pre-processing step before using the dataset for training. There are several renowned DR techniques of which a few are chosen for the comparison analysis below.\n",
    "\n",
    "\n",
    "\n",
    "## 3.1 Principal Component Analysis (PCA):\n",
    "3 different variants of PCA are tried below.\n",
    "\n",
    "## 3.1.1 Normal PCA:\n",
    "PCA converts high dimensional dataset into a lower dimensional dataset while still capturing maximum information in the dataset. It does that by converting n correlated features into k uncorrelated features(components) where k is smaller than n. Furthermore, it ensures that maximum variance is captured by the first component and the second highest variance is captured by the second principal component so this way most of the variance is captured by the first few independent components which are then used to transform the dataset into a lower dimension.\n",
    "\n",
    "## 3.1.2 Sparse PCA(spca):\n",
    "Sparse PCA is another variant of PCA that extract sparse components which can help in reconstruction of data. It overcomes the disadvantage of normal PCA which uses all input features to generate the transformed data, but sparse PCA only uses a few input features to transform the data.\n",
    "\n",
    "\n",
    "## 3.1.3 Incremental PCA(ipca):\n",
    "This is like normal PCA however incremental PCA is for large datasets which might be too large to fit to the memory. Incremental PCA makes a low rank approximation which is not based on the number of samples but only on the number of features.\n",
    "\n",
    "## 3.2 Linear Discriminant Analysis (LDA):\n",
    "Linear Discriminant Analysis utilizes class labels along with the dataset to reduce dimensionality making it a supervised dimensionality reduction technique as opposed to PCA. It is a technique that is used to find linear combination of features that ensure separability of classes. Furthermore, the number of components found are always less than number of classes which means it is a strong dimensionality reduction technique. For example, if LDA was applied on a binary classification dataset, then the resulting components would just be 1. Lastly, this technique is only applicable on classification datasets.\n",
    "\n",
    "\n",
    "## 3.3 Singular value Decomposition(SVD):\n",
    "This technique is like PCA where the only difference is that the matrix factorization is performed on data matrix rather than the covariance matrix which is the case for PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d1af9",
   "metadata": {},
   "source": [
    "# 4. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d80536",
   "metadata": {},
   "source": [
    "\n",
    "Analysis is done on 15 datasets consisting of 8 classification and 7 regression datasets. The project code structure is divided into these two parts Classification and Regression. Each part is also divided further into more sections. In the first section, the datasets are loaded. In the second section, the datasets are pre-processed and lastly in the last section, each dataset goes through the Machine learning analysis using Dimensionality Reduction Techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4270d339",
   "metadata": {},
   "source": [
    "## 4.1 Pre-Processing\n",
    "\n",
    "Once datasets are loaded, each dataset is pre-processed according to its need. A bird's eye view of original dataset is printed before starting its pre-processing.\n",
    "\n",
    "1.\tFirstly, the datatypes and missing values in each column is checked. If any missing values exist, they are addressed by either removing them or imputing them.\n",
    "2.\tUnnecessary columns are removed\n",
    "3.\tCategorical variables are one-hot encoded\n",
    "4.\tAll numerical columns are scaled using a Min-Max Scaler\n",
    "5.\tIf any additional pre-processing is required by any dataset, it is done in the last step.\n",
    "6.\tPredictors are separated from target variable. Convention is to name predictors dataframe as dataset_df and target variable as dataset_classes\n",
    "\n",
    "\n",
    "Finally, the predictors dataset is printed to see how it looks. This process is repeated for all datasets belonging to that section i.e., classification or regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84f3c8",
   "metadata": {},
   "source": [
    "## 4.2 Machine Learning with Dimensionality Reduction\n",
    "\n",
    "After all datasets belonging to that section are pre-processed, machine learning is carried out by trying out various dimensionality reduction techniques.\n",
    "\n",
    "1. Firstly, a pipeline is developed to do the whole analysis and give us final results dataframe. Then, the pipeline is run on all the datasets of that part. Lazy predict library is used to automate running different machine learning models for the classification task and regression task. The pipeline can be broken into 6 parts:\n",
    "        i)  Lazy Predict on dataset with original features\n",
    "        ii) Applying PCA and then running Lazy Predict on resulting dataset.\n",
    "        iii) Applying other PCA variants and then running Lazy Predict on resulting dataset.\n",
    "        iv) Applying LDA and then running resulting dataset (only applicable for classification datasets)\n",
    "        v) Applying SVD and then running resulting dataset\n",
    "        vi) Compiling results from each iteration and output a results dataframe\n",
    "        \n",
    "2. Then, each dataset is passed through the pipeline and its results are exported into an excel sheet.\n",
    "3. Results are printed on the notebook and a detailed analysis is done for the results of that dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514961ac",
   "metadata": {},
   "source": [
    "# 5. Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36dd58b",
   "metadata": {},
   "source": [
    "\n",
    "## 5.1 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd6ebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.75 s (started: 2022-12-30 00:51:41 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Importing Supporting Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "import time\n",
    "from numpy import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autotime\n",
    "\n",
    "#Importing Pre-processing libraries\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importing Dimensionality Reduction Libraries\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA, SparsePCA, TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "#Importing Machine learning Pipeline\n",
    "from lazypredict.Supervised import LazyRegressor, LazyClassifier\n",
    "import lazypredict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec47db",
   "metadata": {},
   "source": [
    "## 5.2 Classification Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7283392d",
   "metadata": {},
   "source": [
    "### 5.2.1 Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0228bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Marketing dataframe is:  (2240, 29)\n",
      "Shape of credit card dataframe is:  (284807, 31)\n",
      "Shape of heart disease dataframe is:  (319795, 18)\n",
      "Shape of diabetes dataframe is:  (101766, 50)\n",
      "Shape of Income dataframe is:  (68378, 15)\n",
      "Shape of Beans dataframe is:  (13611, 17)\n",
      "Shape of Bank Notes dataframe is:  (1372, 5)\n",
      "Shape of audit dataframe is:  (776, 27)\n",
      "time: 4.03 s (started: 2022-12-30 03:32:53 +05:00)\n"
     ]
    }
   ],
   "source": [
    "marketing_df = pd.read_csv('Classification/MarketingDataUCI.csv', sep='\\t')  #Marketing Campaign Dataset\n",
    "credit_df = pd.read_csv('Classification/CreditCardUCI.csv')  #Credit Card Fraud Dataset\n",
    "heart_df = pd.read_csv('Classification/HeartDataUCI.csv')   #Heart disease Dataset\n",
    "diabetic_df = pd.read_csv('Classification/DiabeticDataUCI.csv') #Diabetes Dataset\n",
    "income_df = pd.read_csv('Classification/IncomeDataUCI.csv')  #High Income Prediction\n",
    "beans_df = pd.read_excel('Classification/DryBeanDataUCI.xlsx')   #Drybeans dataset\n",
    "banknotes_df = pd.read_csv('Classification/BankNoteAuthenticationUCI.txt', \n",
    "                           header = None, names = [' variance', 'skewness', \n",
    "                                                   'curtosis', 'entropy', 'Class'])  #Banknotes authentication dataset\n",
    "audit_df = pd.read_csv('Classification/AuditRiskUCI.csv')  #Audit Risk Dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Printing Shape of each dataset\n",
    "print('Shape of Marketing dataframe is: ', marketing_df.shape)   \n",
    "print('Shape of credit card dataframe is: ', credit_df.shape)\n",
    "print('Shape of heart disease dataframe is: ', heart_df.shape)\n",
    "print('Shape of diabetes dataframe is: ', diabetic_df.shape)\n",
    "print('Shape of Income dataframe is: ', income_df.shape)\n",
    "print('Shape of Beans dataframe is: ', beans_df.shape)\n",
    "print('Shape of Bank Notes dataframe is: ', banknotes_df.shape)\n",
    "print('Shape of audit dataframe is: ', audit_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f76632",
   "metadata": {},
   "source": [
    "### 5.2.2 Pre-Processing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e31ae",
   "metadata": {},
   "source": [
    "#### 1. Marketing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee386ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                      0\n",
      "Year_Birth              0\n",
      "Education               0\n",
      "Marital_Status          0\n",
      "Income                 24\n",
      "Kidhome                 0\n",
      "Teenhome                0\n",
      "Dt_Customer             0\n",
      "Recency                 0\n",
      "MntWines                0\n",
      "MntFruits               0\n",
      "MntMeatProducts         0\n",
      "MntFishProducts         0\n",
      "MntSweetProducts        0\n",
      "MntGoldProds            0\n",
      "NumDealsPurchases       0\n",
      "NumWebPurchases         0\n",
      "NumCatalogPurchases     0\n",
      "NumStorePurchases       0\n",
      "NumWebVisitsMonth       0\n",
      "AcceptedCmp3            0\n",
      "AcceptedCmp4            0\n",
      "AcceptedCmp5            0\n",
      "AcceptedCmp1            0\n",
      "AcceptedCmp2            0\n",
      "Complain                0\n",
      "Z_CostContact           0\n",
      "Z_Revenue               0\n",
      "Response                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>04-09-2012</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>08-03-2014</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21-08-2013</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10-02-2014</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19-01-2014</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0  5524        1957  Graduation         Single 58138.00        0         0   \n",
       "1  2174        1954  Graduation         Single 46344.00        1         1   \n",
       "2  4141        1965  Graduation       Together 71613.00        0         0   \n",
       "3  6182        1984  Graduation       Together 26646.00        1         0   \n",
       "4  5324        1981         PhD        Married 58293.00        1         0   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  ...  NumWebVisitsMonth  AcceptedCmp3  \\\n",
       "0  04-09-2012       58       635  ...                  7             0   \n",
       "1  08-03-2014       38        11  ...                  5             0   \n",
       "2  21-08-2013       26       426  ...                  4             0   \n",
       "3  10-02-2014       26        11  ...                  6             0   \n",
       "4  19-01-2014       94       173  ...                  5             0   \n",
       "\n",
       "   AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  \\\n",
       "0             0             0             0             0         0   \n",
       "1             0             0             0             0         0   \n",
       "2             0             0             0             0         0   \n",
       "3             0             0             0             0         0   \n",
       "4             0             0             0             0         0   \n",
       "\n",
       "   Z_CostContact  Z_Revenue  Response  \n",
       "0              3         11         1  \n",
       "1              3         11         0  \n",
       "2              3         11         0  \n",
       "3              3         11         0  \n",
       "4              3         11         0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-30 00:51:49 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(marketing_df.isnull().sum()) #Check missing values\n",
    "marketing_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d42599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (2240, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_Graduation</th>\n",
       "      <th>Education_Master</th>\n",
       "      <th>Education_PhD</th>\n",
       "      <th>Marital_Status_Alone</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Together</th>\n",
       "      <th>Marital_Status_Widow</th>\n",
       "      <th>Marital_Status_YOLO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_Birth  Income  Kidhome  Teenhome  Recency  MntWines  MntFruits  \\\n",
       "0        0.62    0.08     0.00      0.00     0.59      0.43       0.44   \n",
       "1        0.59    0.07     0.50      0.50     0.38      0.01       0.01   \n",
       "2        0.70    0.11     0.00      0.00     0.26      0.29       0.25   \n",
       "3        0.88    0.04     0.50      0.00     0.26      0.01       0.02   \n",
       "4        0.85    0.09     0.50      0.00     0.95      0.12       0.22   \n",
       "\n",
       "   MntMeatProducts  MntFishProducts  MntSweetProducts  ...  \\\n",
       "0             0.32             0.66              0.33  ...   \n",
       "1             0.00             0.01              0.00  ...   \n",
       "2             0.07             0.43              0.08  ...   \n",
       "3             0.01             0.04              0.01  ...   \n",
       "4             0.07             0.18              0.10  ...   \n",
       "\n",
       "   Education_Graduation  Education_Master  Education_PhD  \\\n",
       "0                  1.00              0.00           0.00   \n",
       "1                  1.00              0.00           0.00   \n",
       "2                  1.00              0.00           0.00   \n",
       "3                  1.00              0.00           0.00   \n",
       "4                  0.00              0.00           1.00   \n",
       "\n",
       "   Marital_Status_Alone  Marital_Status_Divorced  Marital_Status_Married  \\\n",
       "0                  0.00                     0.00                    0.00   \n",
       "1                  0.00                     0.00                    0.00   \n",
       "2                  0.00                     0.00                    0.00   \n",
       "3                  0.00                     0.00                    0.00   \n",
       "4                  0.00                     0.00                    1.00   \n",
       "\n",
       "   Marital_Status_Single  Marital_Status_Together  Marital_Status_Widow  \\\n",
       "0                   1.00                     0.00                  0.00   \n",
       "1                   1.00                     0.00                  0.00   \n",
       "2                   0.00                     1.00                  0.00   \n",
       "3                   0.00                     1.00                  0.00   \n",
       "4                   0.00                     0.00                  0.00   \n",
       "\n",
       "   Marital_Status_YOLO  \n",
       "0                 0.00  \n",
       "1                 0.00  \n",
       "2                 0.00  \n",
       "3                 0.00  \n",
       "4                 0.00  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2022-12-30 00:51:49 +05:00)\n"
     ]
    }
   ],
   "source": [
    "marketing_classes = marketing_df[['Response']]\n",
    "marketing_df.drop(columns = ['Response', 'ID', 'Dt_Customer'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#dummy-encoding (One-hot encoding) the categorical variables\n",
    "marketing_df = pd.get_dummies(marketing_df, drop_first = True)\n",
    "marketing_df.shape\n",
    "\n",
    "#Replacing missing values by Nan \n",
    "imputer = SimpleImputer(missing_values=np.nan)\n",
    "imputer = imputer.fit(marketing_df) \n",
    "marketing_df = pd.DataFrame(imputer.transform(marketing_df), columns = (marketing_df.columns)).astype(marketing_df.dtypes.to_dict())\n",
    "\n",
    "#Scaling and One hot Encoding\n",
    "Scaler = MinMaxScaler()\n",
    "marketing_df = pd.get_dummies(marketing_df)\n",
    "marketing_df = pd.DataFrame(Scaler.fit_transform(marketing_df), columns = marketing_df.columns)\n",
    "print('Shape of df now is: ', marketing_df.shape)\n",
    "marketing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b5b98e",
   "metadata": {},
   "source": [
    "#### 2. Credit Card Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e80f0735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "Time      float64\n",
      "V1        float64\n",
      "V2        float64\n",
      "V3        float64\n",
      "V4        float64\n",
      "V5        float64\n",
      "V6        float64\n",
      "V7        float64\n",
      "V8        float64\n",
      "V9        float64\n",
      "V10       float64\n",
      "V11       float64\n",
      "V12       float64\n",
      "V13       float64\n",
      "V14       float64\n",
      "V15       float64\n",
      "V16       float64\n",
      "V17       float64\n",
      "V18       float64\n",
      "V19       float64\n",
      "V20       float64\n",
      "V21       float64\n",
      "V22       float64\n",
      "V23       float64\n",
      "V24       float64\n",
      "V25       float64\n",
      "V26       float64\n",
      "V27       float64\n",
      "V28       float64\n",
      "Amount    float64\n",
      "Class       int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.00</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time    V1    V2   V3    V4    V5    V6    V7    V8    V9  ...   V21   V22  \\\n",
       "0  0.00 -1.36 -0.07 2.54  1.38 -0.34  0.46  0.24  0.10  0.36  ... -0.02  0.28   \n",
       "1  0.00  1.19  0.27 0.17  0.45  0.06 -0.08 -0.08  0.09 -0.26  ... -0.23 -0.64   \n",
       "2  1.00 -1.36 -1.34 1.77  0.38 -0.50  1.80  0.79  0.25 -1.51  ...  0.25  0.77   \n",
       "3  1.00 -0.97 -0.19 1.79 -0.86 -0.01  1.25  0.24  0.38 -1.39  ... -0.11  0.01   \n",
       "4  2.00 -1.16  0.88 1.55  0.40 -0.41  0.10  0.59 -0.27  0.82  ... -0.01  0.80   \n",
       "\n",
       "    V23   V24   V25   V26   V27   V28  Amount  Class  \n",
       "0 -0.11  0.07  0.13 -0.19  0.13 -0.02  149.62      0  \n",
       "1  0.10 -0.34  0.17  0.13 -0.01  0.01    2.69      0  \n",
       "2  0.91 -0.69 -0.33 -0.14 -0.06 -0.06  378.66      0  \n",
       "3 -0.19 -1.18  0.65 -0.22  0.06  0.06  123.50      0  \n",
       "4 -0.14  0.14 -0.21  0.50  0.22  0.22   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2022-12-30 03:34:58 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(credit_df.isnull().sum()) #Check missing values\n",
    "print(credit_df.dtypes)   #Check data types\n",
    "credit_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71258494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-25 18:33:59 +05:00)\n"
     ]
    }
   ],
   "source": [
    "credit_df.Class.value_counts()  #Checking Class Distribution of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4d1d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-25 18:33:59 +05:00)\n"
     ]
    }
   ],
   "source": [
    "credit_df = credit_df.sample(50000)  #Sampling rows from dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de9f2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (50000, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...  V20  V21  V22  V23  \\\n",
       "0 0.97 0.61 0.77 0.34 0.56 0.51 0.54 0.73 0.47 0.51  ... 0.58 0.57 0.37 0.51   \n",
       "1 0.97 0.60 0.75 0.22 0.57 0.58 0.53 0.75 0.43 0.52  ... 0.59 0.58 0.41 0.51   \n",
       "2 0.99 0.60 0.77 0.32 0.55 0.51 0.54 0.74 0.50 0.51  ... 0.58 0.58 0.41 0.52   \n",
       "3 0.97 0.59 0.81 0.31 0.53 0.52 0.52 0.74 0.50 0.51  ... 0.58 0.59 0.49 0.51   \n",
       "4 0.95 0.60 0.82 0.42 0.54 0.54 0.53 0.74 0.51 0.50  ... 0.59 0.59 0.48 0.51   \n",
       "\n",
       "   V24  V25  V26  V27  V28  Amount  \n",
       "0 0.27 0.48 0.44 0.65 0.42    0.00  \n",
       "1 0.56 0.49 0.34 0.65 0.42    0.00  \n",
       "2 0.34 0.39 0.35 0.65 0.42    0.00  \n",
       "3 0.43 0.47 0.40 0.65 0.43    0.00  \n",
       "4 0.45 0.48 0.36 0.65 0.43    0.01  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2022-12-25 18:33:59 +05:00)\n"
     ]
    }
   ],
   "source": [
    "credit_classes = credit_df[['Class']]\n",
    "credit_df.drop(columns = ['Time', 'Class'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#Scaling and One hot Encoding\n",
    "Scaler = MinMaxScaler()\n",
    "credit_df = pd.get_dummies(credit_df)\n",
    "credit_df = pd.DataFrame(Scaler.fit_transform(credit_df), columns = credit_df.columns)\n",
    "print('Shape of df now is: ', credit_df.shape)\n",
    "credit_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b56bd6",
   "metadata": {},
   "source": [
    "#### 3. Heart Disease Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4bf7c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeartDisease        0\n",
      "BMI                 0\n",
      "Smoking             0\n",
      "AlcoholDrinking     0\n",
      "Stroke              0\n",
      "PhysicalHealth      0\n",
      "MentalHealth        0\n",
      "DiffWalking         0\n",
      "Sex                 0\n",
      "AgeCategory         0\n",
      "Race                0\n",
      "Diabetic            0\n",
      "PhysicalActivity    0\n",
      "GenHealth           0\n",
      "SleepTime           0\n",
      "Asthma              0\n",
      "KidneyDisease       0\n",
      "SkinCancer          0\n",
      "dtype: int64\n",
      "HeartDisease         object\n",
      "BMI                 float64\n",
      "Smoking              object\n",
      "AlcoholDrinking      object\n",
      "Stroke               object\n",
      "PhysicalHealth      float64\n",
      "MentalHealth        float64\n",
      "DiffWalking          object\n",
      "Sex                  object\n",
      "AgeCategory          object\n",
      "Race                 object\n",
      "Diabetic             object\n",
      "PhysicalActivity     object\n",
      "GenHealth            object\n",
      "SleepTime           float64\n",
      "Asthma               object\n",
      "KidneyDisease        object\n",
      "SkinCancer           object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Race</th>\n",
       "      <th>Diabetic</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>16.60</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>55-59</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very good</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>20.34</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>80 or older</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very good</td>\n",
       "      <td>7.00</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>26.58</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>20.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>65-69</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fair</td>\n",
       "      <td>8.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>24.21</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>75-79</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Good</td>\n",
       "      <td>6.00</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>23.71</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>40-44</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very good</td>\n",
       "      <td>8.00</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HeartDisease   BMI Smoking AlcoholDrinking Stroke  PhysicalHealth  \\\n",
       "0           No 16.60     Yes              No     No            3.00   \n",
       "1           No 20.34      No              No    Yes            0.00   \n",
       "2           No 26.58     Yes              No     No           20.00   \n",
       "3           No 24.21      No              No     No            0.00   \n",
       "4           No 23.71      No              No     No           28.00   \n",
       "\n",
       "   MentalHealth DiffWalking     Sex  AgeCategory   Race Diabetic  \\\n",
       "0         30.00          No  Female        55-59  White      Yes   \n",
       "1          0.00          No  Female  80 or older  White       No   \n",
       "2         30.00          No    Male        65-69  White      Yes   \n",
       "3          0.00          No  Female        75-79  White       No   \n",
       "4          0.00         Yes  Female        40-44  White       No   \n",
       "\n",
       "  PhysicalActivity  GenHealth  SleepTime Asthma KidneyDisease SkinCancer  \n",
       "0              Yes  Very good       5.00    Yes            No        Yes  \n",
       "1              Yes  Very good       7.00     No            No         No  \n",
       "2              Yes       Fair       8.00    Yes            No         No  \n",
       "3               No       Good       6.00     No            No        Yes  \n",
       "4              Yes  Very good       8.00     No            No         No  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 109 ms (started: 2022-12-30 03:35:03 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(heart_df.isnull().sum()) #Check missing values\n",
    "print(heart_df.dtypes)   #Check data types\n",
    "heart_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24178c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08559545959130067"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32 ms (started: 2022-12-25 18:33:59 +05:00)\n"
     ]
    }
   ],
   "source": [
    "heart_df['HeartDisease'].value_counts()[1]/\n",
    "(heart_df['HeartDisease'].value_counts()[0] +\n",
    " heart_df['HeartDisease'].value_counts()[1])   #Checking Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24d4a293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2022-12-25 18:33:59 +05:00)\n"
     ]
    }
   ],
   "source": [
    "heart_df = heart_df.sample(50000)  #Sampling rows from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09dd31a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (50000, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>Smoking_No</th>\n",
       "      <th>Smoking_Yes</th>\n",
       "      <th>AlcoholDrinking_No</th>\n",
       "      <th>AlcoholDrinking_Yes</th>\n",
       "      <th>Stroke_No</th>\n",
       "      <th>Stroke_Yes</th>\n",
       "      <th>...</th>\n",
       "      <th>GenHealth_Fair</th>\n",
       "      <th>GenHealth_Good</th>\n",
       "      <th>GenHealth_Poor</th>\n",
       "      <th>GenHealth_Very good</th>\n",
       "      <th>Asthma_No</th>\n",
       "      <th>Asthma_Yes</th>\n",
       "      <th>KidneyDisease_No</th>\n",
       "      <th>KidneyDisease_Yes</th>\n",
       "      <th>SkinCancer_No</th>\n",
       "      <th>SkinCancer_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BMI  PhysicalHealth  MentalHealth  SleepTime  Smoking_No  Smoking_Yes  \\\n",
       "0 0.19            0.17          0.33       0.22        1.00         0.00   \n",
       "1 0.28            0.17          0.23       0.30        1.00         0.00   \n",
       "2 0.23            0.67          0.03       0.30        1.00         0.00   \n",
       "3 0.29            0.00          0.00       0.30        0.00         1.00   \n",
       "4 0.13            0.00          0.00       0.22        0.00         1.00   \n",
       "\n",
       "   AlcoholDrinking_No  AlcoholDrinking_Yes  Stroke_No  Stroke_Yes  ...  \\\n",
       "0                1.00                 0.00       1.00        0.00  ...   \n",
       "1                1.00                 0.00       1.00        0.00  ...   \n",
       "2                1.00                 0.00       1.00        0.00  ...   \n",
       "3                1.00                 0.00       1.00        0.00  ...   \n",
       "4                1.00                 0.00       1.00        0.00  ...   \n",
       "\n",
       "   GenHealth_Fair  GenHealth_Good  GenHealth_Poor  GenHealth_Very good  \\\n",
       "0            1.00            0.00            0.00                 0.00   \n",
       "1            0.00            0.00            0.00                 1.00   \n",
       "2            1.00            0.00            0.00                 0.00   \n",
       "3            1.00            0.00            0.00                 0.00   \n",
       "4            0.00            0.00            0.00                 1.00   \n",
       "\n",
       "   Asthma_No  Asthma_Yes  KidneyDisease_No  KidneyDisease_Yes  SkinCancer_No  \\\n",
       "0       1.00        0.00              1.00               0.00           1.00   \n",
       "1       1.00        0.00              1.00               0.00           1.00   \n",
       "2       1.00        0.00              1.00               0.00           1.00   \n",
       "3       1.00        0.00              1.00               0.00           1.00   \n",
       "4       1.00        0.00              1.00               0.00           1.00   \n",
       "\n",
       "   SkinCancer_Yes  \n",
       "0            0.00  \n",
       "1            0.00  \n",
       "2            0.00  \n",
       "3            0.00  \n",
       "4            0.00  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 78 ms (started: 2022-12-25 18:33:59 +05:00)\n"
     ]
    }
   ],
   "source": [
    "heart_classes = heart_df[['HeartDisease']]\n",
    "heart_df.drop(columns = ['HeartDisease'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#Scaling and One hot Encoding\n",
    "Scaler = MinMaxScaler()\n",
    "heart_df = pd.get_dummies(heart_df)\n",
    "heart_df = pd.DataFrame(Scaler.fit_transform(heart_df), columns = heart_df.columns)\n",
    "print('Shape of df now is: ', heart_df.shape)\n",
    "heart_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30ef9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-25 18:34:01 +05:00)\n"
     ]
    }
   ],
   "source": [
    "heart_classes.loc[\n",
    "    ((heart_classes['HeartDisease'] == 'Yes')), 'HeartDisease'] = 1     #Labeling the Yes case\n",
    "\n",
    "heart_classes.loc[\n",
    "    ((heart_classes['HeartDisease'] == 'No')), 'HeartDisease'] = 0   #Labeling the No case    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2a460",
   "metadata": {},
   "source": [
    "#### 4. Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef32cfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encounter_id                    0\n",
      "patient_nbr                     0\n",
      "race                         2273\n",
      "gender                          0\n",
      "age                             0\n",
      "weight                      98569\n",
      "admission_type_id               0\n",
      "discharge_disposition_id        0\n",
      "admission_source_id             0\n",
      "time_in_hospital                0\n",
      "payer_code                  40256\n",
      "medical_specialty           49949\n",
      "num_lab_procedures              0\n",
      "num_procedures                  0\n",
      "num_medications                 0\n",
      "number_outpatient               0\n",
      "number_emergency                0\n",
      "number_inpatient                0\n",
      "diag_1                       1666\n",
      "diag_2                       2894\n",
      "diag_3                       6481\n",
      "number_diagnoses                0\n",
      "max_glu_serum                   0\n",
      "A1Cresult                       0\n",
      "metformin                       0\n",
      "repaglinide                     0\n",
      "nateglinide                     0\n",
      "chlorpropamide                  0\n",
      "glimepiride                     0\n",
      "acetohexamide                   0\n",
      "glipizide                       0\n",
      "glyburide                       0\n",
      "tolbutamide                     0\n",
      "pioglitazone                    0\n",
      "rosiglitazone                   0\n",
      "acarbose                        0\n",
      "miglitol                        0\n",
      "troglitazone                    0\n",
      "tolazamide                      0\n",
      "examide                         0\n",
      "citoglipton                     0\n",
      "insulin                         0\n",
      "glyburide-metformin             0\n",
      "glipizide-metformin             0\n",
      "glimepiride-pioglitazone        0\n",
      "metformin-rosiglitazone         0\n",
      "metformin-pioglitazone          0\n",
      "change                          0\n",
      "diabetesMed                     0\n",
      "readmitted                      0\n",
      "dtype: int64\n",
      "encounter_id                  int64\n",
      "patient_nbr                   int64\n",
      "race                         object\n",
      "gender                       object\n",
      "age                          object\n",
      "weight                       object\n",
      "admission_type_id             int64\n",
      "discharge_disposition_id      int64\n",
      "admission_source_id           int64\n",
      "time_in_hospital              int64\n",
      "payer_code                   object\n",
      "medical_specialty            object\n",
      "num_lab_procedures            int64\n",
      "num_procedures                int64\n",
      "num_medications               int64\n",
      "number_outpatient             int64\n",
      "number_emergency              int64\n",
      "number_inpatient              int64\n",
      "diag_1                      float64\n",
      "diag_2                      float64\n",
      "diag_3                      float64\n",
      "number_diagnoses              int64\n",
      "max_glu_serum                object\n",
      "A1Cresult                    object\n",
      "metformin                    object\n",
      "repaglinide                  object\n",
      "nateglinide                  object\n",
      "chlorpropamide               object\n",
      "glimepiride                  object\n",
      "acetohexamide                object\n",
      "glipizide                    object\n",
      "glyburide                    object\n",
      "tolbutamide                  object\n",
      "pioglitazone                 object\n",
      "rosiglitazone                object\n",
      "acarbose                     object\n",
      "miglitol                     object\n",
      "troglitazone                 object\n",
      "tolazamide                   object\n",
      "examide                      object\n",
      "citoglipton                  object\n",
      "insulin                      object\n",
      "glyburide-metformin          object\n",
      "glipizide-metformin          object\n",
      "glimepiride-pioglitazone     object\n",
      "metformin-rosiglitazone      object\n",
      "metformin-pioglitazone       object\n",
      "change                       object\n",
      "diabetesMed                  object\n",
      "readmitted                   object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)    NaN   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)    NaN   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)    NaN   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)    NaN   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)    NaN   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1  ...          No      No                   No   \n",
       "1                 3  ...          No      Up                   No   \n",
       "2                 2  ...          No      No                   No   \n",
       "3                 2  ...          No      Up                   No   \n",
       "4                 1  ...          No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change  diabetesMed  readmitted  \n",
       "0                      No      No           No          NO  \n",
       "1                      No      Ch          Yes         >30  \n",
       "2                      No      No          Yes          NO  \n",
       "3                      No      Ch          Yes          NO  \n",
       "4                      No      Ch          Yes          NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 281 ms (started: 2022-12-25 21:11:30 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Changing diag_1, diag_2 and diag_3 to numeric\n",
    "diabetic_df[['diag_1', 'diag_2', 'diag_3']] = diabetic_df[['diag_1', 'diag_2', 'diag_3']].apply(pd.to_numeric, errors = 'coerce') \n",
    "\n",
    "#Replacing all missing values with Nan\n",
    "diabetic_df = diabetic_df.replace('?', np.nan)\n",
    "\n",
    "print(diabetic_df.isnull().sum()) #Check missing values\n",
    "print(diabetic_df.dtypes)   #Check data types\n",
    "diabetic_df.head()  #Bird's eye view of dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53cee412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 62 ms (started: 2022-12-25 21:11:31 +05:00)\n"
     ]
    }
   ],
   "source": [
    "diabetic_df = diabetic_df.sample(50000)  #sampling rows from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6ab3cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (50000, 77)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>...</th>\n",
       "      <th>insulin_Steady</th>\n",
       "      <th>insulin_Up</th>\n",
       "      <th>glyburide-metformin_No</th>\n",
       "      <th>glyburide-metformin_Steady</th>\n",
       "      <th>glyburide-metformin_Up</th>\n",
       "      <th>glipizide-metformin_Steady</th>\n",
       "      <th>metformin-rosiglitazone_Steady</th>\n",
       "      <th>change_No</th>\n",
       "      <th>readmitted_&gt;30</th>\n",
       "      <th>readmitted_NO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0              0.15                0.00            0.00             0.16   \n",
       "1              0.54                0.44            0.17             0.19   \n",
       "2              0.38                0.11            0.50             0.23   \n",
       "3              0.15                0.30            0.33             0.17   \n",
       "4              0.77                0.40            0.50             0.33   \n",
       "\n",
       "   number_outpatient  number_emergency  number_inpatient  diag_1  diag_2  \\\n",
       "0               0.00              0.00              0.00    0.25    0.71   \n",
       "1               0.00              0.00              0.00    1.00    0.71   \n",
       "2               0.11              0.00              0.00    0.57    0.57   \n",
       "3               0.03              0.08              0.19    0.58    0.48   \n",
       "4               0.00              0.00              0.00    0.73    0.25   \n",
       "\n",
       "   diag_3  ...  insulin_Steady  insulin_Up  glyburide-metformin_No  \\\n",
       "0    0.68  ...            1.00        0.00                    1.00   \n",
       "1    0.25  ...            1.00        0.00                    1.00   \n",
       "2    0.51  ...            0.00        0.00                    1.00   \n",
       "3    0.25  ...            0.00        0.00                    1.00   \n",
       "4    0.41  ...            0.00        1.00                    1.00   \n",
       "\n",
       "   glyburide-metformin_Steady  glyburide-metformin_Up  \\\n",
       "0                        0.00                    0.00   \n",
       "1                        0.00                    0.00   \n",
       "2                        0.00                    0.00   \n",
       "3                        0.00                    0.00   \n",
       "4                        0.00                    0.00   \n",
       "\n",
       "   glipizide-metformin_Steady  metformin-rosiglitazone_Steady  change_No  \\\n",
       "0                        0.00                            0.00       0.00   \n",
       "1                        0.00                            0.00       1.00   \n",
       "2                        0.00                            0.00       0.00   \n",
       "3                        0.00                            0.00       0.00   \n",
       "4                        0.00                            0.00       0.00   \n",
       "\n",
       "   readmitted_>30  readmitted_NO  \n",
       "0            0.00           1.00  \n",
       "1            0.00           1.00  \n",
       "2            0.00           1.00  \n",
       "3            1.00           0.00  \n",
       "4            0.00           1.00  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 375 ms (started: 2022-12-25 21:11:34 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Dropping all the ID columns and columns with a lot of missing values\n",
    "diabetic_classes = diabetic_df[['diabetesMed']]\n",
    "diabetic_df.drop(columns = ['diabetesMed', 'encounter_id', ''  'patient_nbr', 'weight', 'admission_type_id', 'discharge_disposition_id',\n",
    "       'admission_source_id', 'payer_code', 'medical_specialty', 'encounter_id'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#Replacing missing values by Nan \n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer = imputer.fit(diabetic_df) \n",
    "diabetic_df = pd.DataFrame(imputer.transform(diabetic_df), columns = (diabetic_df.columns)).astype(diabetic_df.dtypes.to_dict())\n",
    "\n",
    "#dummy-encoding (One-hot encoding) the categorical variables\n",
    "diabetic_df = pd.get_dummies(diabetic_df, drop_first = True)\n",
    "diabetic_df.shape\n",
    "\n",
    "\n",
    "#Scaling and One hot Encoding\n",
    "Scaler = MinMaxScaler()\n",
    "diabetic_df = pd.get_dummies(diabetic_df)\n",
    "diabetic_df = pd.DataFrame(Scaler.fit_transform(diabetic_df), columns = diabetic_df.columns)\n",
    "print('Shape of df now is: ', diabetic_df.shape)\n",
    "diabetic_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dafbd285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-25 21:11:37 +05:00)\n"
     ]
    }
   ],
   "source": [
    "diabetic_classes.loc[\n",
    "    ((diabetic_classes['diabetesMed'] == 'Yes')), 'diabetesMed'] = 1     #Labeling the Yes case\n",
    "\n",
    "diabetic_classes.loc[\n",
    "    ((diabetic_classes['diabetesMed'] == 'No')), 'diabetesMed'] = 0   #Labeling the No case\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fef643",
   "metadata": {},
   "source": [
    "#### 5. Income Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27af9275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row ID                    0\n",
      "Age                       0\n",
      "WorkClass                 0\n",
      "X1                        0\n",
      "Education Level           0\n",
      "X2                        0\n",
      "Marital Status            0\n",
      "Occupation                0\n",
      "X3                        0\n",
      "Gender                    0\n",
      "X4                        0\n",
      "X5                        0\n",
      "Hours Per Week Working    0\n",
      "Native Country            0\n",
      "High Income               0\n",
      "dtype: int64\n",
      "row ID                     object\n",
      "Age                       float64\n",
      "WorkClass                   int64\n",
      "X1                        float64\n",
      "Education Level             int64\n",
      "X2                        float64\n",
      "Marital Status              int64\n",
      "Occupation                  int64\n",
      "X3                          int64\n",
      "Gender                      int64\n",
      "X4                        float64\n",
      "X5                        float64\n",
      "Hours Per Week Working    float64\n",
      "Native Country              int64\n",
      "High Income                 int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>WorkClass</th>\n",
       "      <th>X1</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>X2</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>X3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>Hours Per Week Working</th>\n",
       "      <th>Native Country</th>\n",
       "      <th>High Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Row2</td>\n",
       "      <td>38.00</td>\n",
       "      <td>2</td>\n",
       "      <td>215646.00</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Row3</td>\n",
       "      <td>53.00</td>\n",
       "      <td>2</td>\n",
       "      <td>234721.00</td>\n",
       "      <td>2</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Row5</td>\n",
       "      <td>37.00</td>\n",
       "      <td>2</td>\n",
       "      <td>284582.00</td>\n",
       "      <td>3</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Row7</td>\n",
       "      <td>52.00</td>\n",
       "      <td>1</td>\n",
       "      <td>209642.00</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Row8</td>\n",
       "      <td>31.00</td>\n",
       "      <td>2</td>\n",
       "      <td>45781.00</td>\n",
       "      <td>3</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14084.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row ID   Age  WorkClass        X1  Education Level    X2  Marital Status  \\\n",
       "0   Row2 38.00          2 215646.00                1  9.00               2   \n",
       "1   Row3 53.00          2 234721.00                2  7.00               1   \n",
       "2   Row5 37.00          2 284582.00                3 14.00               1   \n",
       "3   Row7 52.00          1 209642.00                1  9.00               1   \n",
       "4   Row8 31.00          2  45781.00                3 14.00               0   \n",
       "\n",
       "   Occupation  X3  Gender       X4   X5  Hours Per Week Working  \\\n",
       "0           2   0       0     0.00 0.00                   40.00   \n",
       "1           2   1       0     0.00 0.00                   40.00   \n",
       "2           1   0       1     0.00 0.00                   40.00   \n",
       "3           1   0       0     0.00 0.00                   45.00   \n",
       "4           3   0       1 14084.00 0.00                   50.00   \n",
       "\n",
       "   Native Country  High Income  \n",
       "0               0            0  \n",
       "1               0            0  \n",
       "2               0            0  \n",
       "3               0            1  \n",
       "4               0            1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-25 21:11:39 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(income_df.isnull().sum()) #Check missing values\n",
    "print(income_df.dtypes)   #Check data types\n",
    "income_df.head()  #Bird's eye view of dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab3cd59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-25 21:11:39 +05:00)\n"
     ]
    }
   ],
   "source": [
    "income_df = income_df.sample(40000) #sampling rows from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3b0306c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (40000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>WorkClass</th>\n",
       "      <th>X1</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>X2</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>X3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>Hours Per Week Working</th>\n",
       "      <th>Native Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  WorkClass   X1  Education Level   X2  Marital Status  Occupation   X3  \\\n",
       "0 0.15       0.62 0.09             0.07 0.53            0.00        0.79 0.00   \n",
       "1 0.58       0.25 0.24             0.27 0.27            0.17        0.29 0.00   \n",
       "2 0.29       0.75 0.47             0.67 0.53            0.67        0.21 0.25   \n",
       "3 0.10       0.25 0.21             0.80 0.47            0.00        0.29 0.25   \n",
       "4 0.25       0.25 0.06             0.07 0.74            0.00        0.43 0.00   \n",
       "\n",
       "   Gender   X4   X5  Hours Per Week Working  Native Country  \n",
       "0    1.00 0.01 0.00                    0.32            0.00  \n",
       "1    0.00 0.00 0.00                    0.30            0.00  \n",
       "2    0.00 0.24 0.14                    0.24            0.00  \n",
       "3    0.00 0.00 0.00                    0.32            0.00  \n",
       "4    0.00 0.02 0.00                    0.42            0.00  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-25 21:11:40 +05:00)\n"
     ]
    }
   ],
   "source": [
    "income_classes = income_df[['High Income']]\n",
    "income_df.drop(columns = ['High Income', 'row ID'], inplace = True)  #Dropping unnecessary columns \n",
    "\n",
    "#Scaling and One hot Encoding\n",
    "Scaler = MinMaxScaler()\n",
    "income_df = pd.get_dummies(income_df)\n",
    "income_df = pd.DataFrame(Scaler.fit_transform(income_df), columns = income_df.columns)\n",
    "print('Shape of df now is: ', income_df.shape)\n",
    "income_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c40d3",
   "metadata": {},
   "source": [
    "#### 6. Dry Beans Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "0a9785f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area               0\n",
      "Perimeter          0\n",
      "MajorAxisLength    0\n",
      "MinorAxisLength    0\n",
      "AspectRation       0\n",
      "Eccentricity       0\n",
      "ConvexArea         0\n",
      "EquivDiameter      0\n",
      "Extent             0\n",
      "Solidity           0\n",
      "roundness          0\n",
      "Compactness        0\n",
      "ShapeFactor1       0\n",
      "ShapeFactor2       0\n",
      "ShapeFactor3       0\n",
      "ShapeFactor4       0\n",
      "Class              0\n",
      "dtype: int64\n",
      "Area                 int64\n",
      "Perimeter          float64\n",
      "MajorAxisLength    float64\n",
      "MinorAxisLength    float64\n",
      "AspectRation       float64\n",
      "Eccentricity       float64\n",
      "ConvexArea           int64\n",
      "EquivDiameter      float64\n",
      "Extent             float64\n",
      "Solidity           float64\n",
      "roundness          float64\n",
      "Compactness        float64\n",
      "ShapeFactor1       float64\n",
      "ShapeFactor2       float64\n",
      "ShapeFactor3       float64\n",
      "ShapeFactor4       float64\n",
      "Class               object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28395</td>\n",
       "      <td>610.29</td>\n",
       "      <td>208.18</td>\n",
       "      <td>173.89</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.55</td>\n",
       "      <td>28715</td>\n",
       "      <td>190.14</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28734</td>\n",
       "      <td>638.02</td>\n",
       "      <td>200.52</td>\n",
       "      <td>182.73</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.41</td>\n",
       "      <td>29172</td>\n",
       "      <td>191.27</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29380</td>\n",
       "      <td>624.11</td>\n",
       "      <td>212.83</td>\n",
       "      <td>175.93</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.56</td>\n",
       "      <td>29690</td>\n",
       "      <td>193.41</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30008</td>\n",
       "      <td>645.88</td>\n",
       "      <td>210.56</td>\n",
       "      <td>182.52</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>30724</td>\n",
       "      <td>195.47</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.99</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30140</td>\n",
       "      <td>620.13</td>\n",
       "      <td>201.85</td>\n",
       "      <td>190.28</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.33</td>\n",
       "      <td>30417</td>\n",
       "      <td>195.90</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0  28395     610.29           208.18           173.89          1.20   \n",
       "1  28734     638.02           200.52           182.73          1.10   \n",
       "2  29380     624.11           212.83           175.93          1.21   \n",
       "3  30008     645.88           210.56           182.52          1.15   \n",
       "4  30140     620.13           201.85           190.28          1.06   \n",
       "\n",
       "   Eccentricity  ConvexArea  EquivDiameter  Extent  Solidity  roundness  \\\n",
       "0          0.55       28715         190.14    0.76      0.99       0.96   \n",
       "1          0.41       29172         191.27    0.78      0.98       0.89   \n",
       "2          0.56       29690         193.41    0.78      0.99       0.95   \n",
       "3          0.50       30724         195.47    0.78      0.98       0.90   \n",
       "4          0.33       30417         195.90    0.77      0.99       0.98   \n",
       "\n",
       "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
       "0         0.91          0.01          0.00          0.83          1.00  SEKER  \n",
       "1         0.95          0.01          0.00          0.91          1.00  SEKER  \n",
       "2         0.91          0.01          0.00          0.83          1.00  SEKER  \n",
       "3         0.93          0.01          0.00          0.86          0.99  SEKER  \n",
       "4         0.97          0.01          0.00          0.94          1.00  SEKER  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-29 01:01:20 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(beans_df.isnull().sum()) #Check missing values\n",
    "print(beans_df.dtypes)   #Check data types\n",
    "beans_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "4573d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (13611, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0  0.03       0.06             0.04             0.15          0.12   \n",
       "1  0.04       0.08             0.03             0.18          0.05   \n",
       "2  0.04       0.07             0.05             0.16          0.13   \n",
       "3  0.04       0.08             0.05             0.18          0.09   \n",
       "4  0.04       0.07             0.03             0.20          0.03   \n",
       "\n",
       "   Eccentricity  ConvexArea  EquivDiameter  Extent  Solidity  roundness  \\\n",
       "0          0.48        0.03           0.07    0.67      0.92       0.93   \n",
       "1          0.28        0.03           0.07    0.74      0.87       0.79   \n",
       "2          0.50        0.04           0.08    0.72      0.93       0.91   \n",
       "3          0.40        0.04           0.08    0.73      0.76       0.83   \n",
       "4          0.17        0.04           0.08    0.70      0.95       0.99   \n",
       "\n",
       "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n",
       "0         0.79          0.59          0.83          0.75          0.98  \n",
       "1         0.90          0.55          0.97          0.88          0.97  \n",
       "2         0.77          0.58          0.80          0.74          0.99  \n",
       "3         0.83          0.55          0.85          0.80          0.89  \n",
       "4         0.95          0.51          1.00          0.94          0.99  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-29 01:01:26 +05:00)\n"
     ]
    }
   ],
   "source": [
    "beans_classes = beans_df[['Class']]\n",
    "beans_df.drop(columns = ['Class'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#Label encoding the Y variable\n",
    "le = LabelEncoder()\n",
    "beans_classes = pd.DataFrame(le.fit_transform(beans_classes), columns = beans_classes.columns)\n",
    "\n",
    "\n",
    "#Scaling and One hot Encoding\n",
    "Scaler = MinMaxScaler()\n",
    "beans_df = pd.get_dummies(beans_df)\n",
    "beans_df = pd.DataFrame(Scaler.fit_transform(beans_df), columns = beans_df.columns)\n",
    "print('Shape of df now is: ', beans_df.shape)\n",
    "beans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec284e6d",
   "metadata": {},
   "source": [
    "#### 7. Bank Notes Detection Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "23fe6873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " variance    0\n",
      "skewness     0\n",
      "curtosis     0\n",
      "entropy      0\n",
      "Class        0\n",
      "dtype: int64\n",
      " variance    float64\n",
      "skewness     float64\n",
      "curtosis     float64\n",
      "entropy      float64\n",
      "Class          int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62</td>\n",
       "      <td>8.67</td>\n",
       "      <td>-2.81</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.55</td>\n",
       "      <td>8.17</td>\n",
       "      <td>-2.46</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.87</td>\n",
       "      <td>-2.64</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.46</td>\n",
       "      <td>9.52</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>-3.59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.33</td>\n",
       "      <td>-4.46</td>\n",
       "      <td>4.57</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variance  skewness  curtosis  entropy  Class\n",
       "0       3.62      8.67     -2.81    -0.45      0\n",
       "1       4.55      8.17     -2.46    -1.46      0\n",
       "2       3.87     -2.64      1.92     0.11      0\n",
       "3       3.46      9.52     -4.01    -3.59      0\n",
       "4       0.33     -4.46      4.57    -0.99      0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 01:52:46 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(banknotes_df.isnull().sum()) #Check missing values\n",
    "print(banknotes_df.dtypes)   #Check data types\n",
    "banknotes_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e6239d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (1372, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variance  skewness  curtosis  entropy\n",
       "0       0.77      0.84      0.11     0.74\n",
       "1       0.84      0.82      0.12     0.64\n",
       "2       0.79      0.42      0.31     0.79\n",
       "3       0.76      0.87      0.05     0.45\n",
       "4       0.53      0.35      0.42     0.69"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-26 01:52:47 +05:00)\n"
     ]
    }
   ],
   "source": [
    "banknotes_classes = banknotes_df[['Class']]\n",
    "banknotes_df.drop(columns = ['Class'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#Scaling and One hot Encoding\n",
    "Scaler = MinMaxScaler()\n",
    "banknotes_df = pd.get_dummies(banknotes_df)\n",
    "banknotes_df = pd.DataFrame(Scaler.fit_transform(banknotes_df), columns = banknotes_df.columns)\n",
    "print('Shape of df now is: ', banknotes_df.shape)\n",
    "banknotes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121b38fe",
   "metadata": {},
   "source": [
    "#### 8. Audit Risk Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6912bdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector_score      0\n",
      "LOCATION_ID       0\n",
      "PARA_A            0\n",
      "Score_A           0\n",
      "Risk_A            0\n",
      "PARA_B            0\n",
      "Score_B           0\n",
      "Risk_B            0\n",
      "TOTAL             0\n",
      "numbers           0\n",
      "Score_B.1         0\n",
      "Risk_C            0\n",
      "Money_Value       1\n",
      "Score_MV          0\n",
      "Risk_D            0\n",
      "District_Loss     0\n",
      "PROB              0\n",
      "RiSk_E            0\n",
      "History           0\n",
      "Prob              0\n",
      "Risk_F            0\n",
      "Score             0\n",
      "Inherent_Risk     0\n",
      "CONTROL_RISK      0\n",
      "Detection_Risk    0\n",
      "Audit_Risk        0\n",
      "Risk              0\n",
      "dtype: int64\n",
      "Sector_score      float64\n",
      "LOCATION_ID        object\n",
      "PARA_A            float64\n",
      "Score_A           float64\n",
      "Risk_A            float64\n",
      "PARA_B            float64\n",
      "Score_B           float64\n",
      "Risk_B            float64\n",
      "TOTAL             float64\n",
      "numbers           float64\n",
      "Score_B.1         float64\n",
      "Risk_C            float64\n",
      "Money_Value       float64\n",
      "Score_MV          float64\n",
      "Risk_D            float64\n",
      "District_Loss       int64\n",
      "PROB              float64\n",
      "RiSk_E            float64\n",
      "History             int64\n",
      "Prob              float64\n",
      "Risk_F            float64\n",
      "Score             float64\n",
      "Inherent_Risk     float64\n",
      "CONTROL_RISK      float64\n",
      "Detection_Risk    float64\n",
      "Audit_Risk        float64\n",
      "Risk                int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>...</th>\n",
       "      <th>RiSk_E</th>\n",
       "      <th>History</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Risk_F</th>\n",
       "      <th>Score</th>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>Detection_Risk</th>\n",
       "      <th>Audit_Risk</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>23</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>8.57</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.97</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>6.48</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>17.53</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sector_score LOCATION_ID  PARA_A  Score_A  Risk_A  PARA_B  Score_B  Risk_B  \\\n",
       "0          3.89          23    4.18     0.60    2.51    2.50     0.20    0.50   \n",
       "1          3.89           6    0.00     0.20    0.00    4.83     0.20    0.97   \n",
       "2          3.89           6    0.51     0.20    0.10    0.23     0.20    0.05   \n",
       "3          3.89           6    0.00     0.20    0.00   10.80     0.60    6.48   \n",
       "4          3.89           6    0.00     0.20    0.00    0.08     0.20    0.02   \n",
       "\n",
       "   TOTAL  numbers  ...  RiSk_E  History  Prob  Risk_F  Score  Inherent_Risk  \\\n",
       "0   6.68     5.00  ...    0.40        0  0.20    0.00   2.40           8.57   \n",
       "1   4.83     5.00  ...    0.40        0  0.20    0.00   2.00           2.55   \n",
       "2   0.74     5.00  ...    0.40        0  0.20    0.00   2.00           1.55   \n",
       "3  10.80     6.00  ...    0.40        0  0.20    0.00   4.40          17.53   \n",
       "4   0.08     5.00  ...    0.40        0  0.20    0.00   2.00           1.42   \n",
       "\n",
       "   CONTROL_RISK  Detection_Risk  Audit_Risk  Risk  \n",
       "0          0.40            0.50        1.71     1  \n",
       "1          0.40            0.50        0.51     0  \n",
       "2          0.40            0.50        0.31     0  \n",
       "3          0.40            0.50        3.51     1  \n",
       "4          0.40            0.50        0.28     0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-26 01:52:49 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(audit_df.isnull().sum()) #Check missing values\n",
    "print(audit_df.dtypes)   #Check data types\n",
    "audit_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5606e200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (775, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Score_B.1</th>\n",
       "      <th>...</th>\n",
       "      <th>PROB</th>\n",
       "      <th>RiSk_E</th>\n",
       "      <th>History</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Risk_F</th>\n",
       "      <th>Score</th>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>Detection_Risk</th>\n",
       "      <th>Audit_Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sector_score  PARA_A  Score_A  Risk_A  PARA_B  Score_B  Risk_B  TOTAL  \\\n",
       "0          0.04    0.05     1.00    0.05    0.00     0.00    0.00   0.01   \n",
       "1          0.04    0.00     0.00    0.00    0.00     0.00    0.00   0.00   \n",
       "2          0.04    0.01     0.00    0.00    0.00     0.00    0.00   0.00   \n",
       "3          0.04    0.00     0.00    0.00    0.01     1.00    0.01   0.01   \n",
       "4          0.04    0.00     0.00    0.00    0.00     0.00    0.00   0.00   \n",
       "\n",
       "   numbers  Score_B.1  ...  PROB  RiSk_E  History  Prob  Risk_F  Score  \\\n",
       "0     0.00       0.00  ...  0.00    0.00     0.00  0.00    0.00   0.12   \n",
       "1     0.00       0.00  ...  0.00    0.00     0.00  0.00    0.00   0.00   \n",
       "2     0.00       0.00  ...  0.00    0.00     0.00  0.00    0.00   0.00   \n",
       "3     0.25       1.00  ...  0.00    0.00     0.00  0.00    0.00   0.75   \n",
       "4     0.00       0.00  ...  0.00    0.00     0.00  0.00    0.00   0.00   \n",
       "\n",
       "   Inherent_Risk  CONTROL_RISK  Detection_Risk  Audit_Risk  \n",
       "0           0.01          0.00            0.00        0.00  \n",
       "1           0.00          0.00            0.00        0.00  \n",
       "2           0.00          0.00            0.00        0.00  \n",
       "3           0.02          0.00            0.00        0.00  \n",
       "4           0.00          0.00            0.00        0.00  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-26 01:57:02 +05:00)\n"
     ]
    }
   ],
   "source": [
    "audit_df = audit_df.dropna()\n",
    "audit_classes = audit_df[['Risk']]\n",
    "audit_df.drop(columns = ['Risk', 'LOCATION_ID'], inplace = True)  #Dropping unnecessary columns \n",
    "\n",
    "#Scaling and One hot Encoding\n",
    "Scaler = MinMaxScaler()\n",
    "audit_df = pd.get_dummies(audit_df)\n",
    "audit_df = pd.DataFrame(Scaler.fit_transform(audit_df), columns = audit_df.columns)\n",
    "print('Shape of df now is: ', audit_df.shape)\n",
    "audit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cb3006",
   "metadata": {},
   "source": [
    "### 5.2.3 Dimensionality Reduction Techniques with ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b0bbdf",
   "metadata": {},
   "source": [
    "#### A) Dimensionality Reduction Pipeline for Classification datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "be910c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-29 01:02:04 +05:00)\n"
     ]
    }
   ],
   "source": [
    "def dimensionality_reduction_classification(X_train, y_train, X_test, y_test, pca_dim = 0.95, ipca_dim= 0.95, svd_dim = 0.95):\n",
    "    \n",
    "    print(\"Starting DR Pipeline...\")\n",
    "\n",
    "    print(\"1. Running Lazy Predict without DR\")\n",
    "    \n",
    "#Running Lazy Predict without Dimensionality Reduction:\n",
    "    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric = None)\n",
    "    simple_models = clf.fit(X_train, X_test, y_train, y_test)[0].sort_index()\n",
    "    simple_models['dim'] = X_train.shape[1]\n",
    "    simple_models.drop(columns = ['Balanced Accuracy', 'Time Taken'], inplace = True)\n",
    "    \n",
    "    print(\"Success!\")    \n",
    "\n",
    "#Model Performances with PCA:\n",
    "    \n",
    "    #Running PCA:\n",
    "    print(\"2. Running PCA\") \n",
    "    pca = PCA(n_components = pca_dim)\n",
    "    pca.fit(X_train)\n",
    "    X_train_transformed = pca.transform(X_train)\n",
    "    X_test_transformed = pca.transform(X_test)\n",
    "    print(\"Success!\")    \n",
    "    \n",
    "    #Running Lazy Predict with PCA\n",
    "    print(\"3. Running Lazy Predict on PCA dataset\") \n",
    "    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric = None)\n",
    "    pcamodels = clf.fit(X_train_transformed, X_test_transformed, y_train, y_test)[0].sort_index()\n",
    "    pcamodels.drop(columns = ['Balanced Accuracy', 'Time Taken'], inplace = True)\n",
    "    pcamodels['dims'] = len(pca.components_)\n",
    "    print(\"Success!\")    \n",
    "\n",
    "    \n",
    "#Model Performances with Incremental-PCA:\n",
    "\n",
    "    #Running Incremental PCA:\n",
    "    print(\"4. Running Incremental PCA\") \n",
    "    for i in range(1, X_train.shape[1], 1):\n",
    "        ipca = IncrementalPCA(n_components = i)\n",
    "        ipca.fit(X_train)\n",
    "        X_train_transformed = ipca.transform(X_train)\n",
    "        X_test_transformed = ipca.transform(X_test)\n",
    "        \n",
    "        if ipca.explained_variance_ratio_.sum() >= ipca_dim:\n",
    "            print(\"Success!\")\n",
    "            print(\"5. Running Lazy Predict on Incremental PCA dataset\") \n",
    "            clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric = None)     #Running Lazy Predict after SVD\n",
    "            ipcamodels = clf.fit(X_train_transformed, X_test_transformed, y_train, y_test)[0].sort_index()\n",
    "            ipcamodels.drop(columns = ['Balanced Accuracy', 'Time Taken'], inplace = True)\n",
    "            ipcamodels['dims'] = ipca.n_components_\n",
    "            print(\"Success!\")\n",
    "            break\n",
    "    \n",
    "#Model Performances with Sparse-PCA:\n",
    "    print(\"6. Running Sparse PCA\")     \n",
    "    spca = SparsePCA(n_components = 10)\n",
    "    spca.fit(X_train)\n",
    "    X_train_transformed = spca.transform(X_train)\n",
    "    X_test_transformed = spca.transform(X_test)\n",
    "    print(\"Success!\")\n",
    "    \n",
    "    #Running Lazy Predict Sparse PCA:\n",
    "    print(\"7. Running Lazy Predict on Sparse PCA dataset\") \n",
    "    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric = None)     #Running Lazy Predict after SVD\n",
    "    spcamodels = clf.fit(X_train_transformed, X_test_transformed, y_train, y_test)[0].sort_index()\n",
    "    spcamodels.drop(columns = ['Balanced Accuracy', 'Time Taken'], inplace = True)\n",
    "    spcamodels['dims'] = spca.n_components_    \n",
    "    print(\"Success!\")\n",
    "    \n",
    "#Model Performances with LDA:\n",
    "\n",
    "    #Running LDA:\n",
    "    print(\"8. Running LDA\")    \n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X_train, y_train)\n",
    "    X_train_transformed = lda.transform(X_train)\n",
    "    X_test_transformed = lda.transform(X_test)\n",
    "    print(\"Success!\")\n",
    "    \n",
    "    #Running Lazy Predict with LDA\n",
    "    print(\"9. Running Lazy Predict on LDA dataset\")\n",
    "    clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric = None)\n",
    "    ldamodels = clf.fit(X_train_transformed, X_test_transformed, y_train, y_test)[0].sort_index()\n",
    "    ldamodels.drop(columns = ['Balanced Accuracy', 'Time Taken'], inplace = True)\n",
    "    ldamodels['dims'] = len(lda.coef_)\n",
    "    print(\"Success!\")\n",
    "#Model Performances with SVD:\n",
    "\n",
    "    #Running SVD:\n",
    "    print(\"10. Running SVD\")        \n",
    "    for i in range(1, X_train.shape[1], 1):\n",
    "        svd = TruncatedSVD(n_components = i)\n",
    "        svd.fit(X_train)\n",
    "        X_train_transformed = svd.transform(X_train)\n",
    "        X_test_transformed = svd.transform(X_test)\n",
    "        \n",
    "        if svd.explained_variance_ratio_.sum() >= svd_dim or i>=X_train.shape[1]-1:\n",
    "            print(\"Success!\")\n",
    "            print(\"11. Running Lazy Predict on SVD dataset\")\n",
    "            clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric = None)     #Running Lazy Predict after SVD\n",
    "            svdmodels = clf.fit(X_train_transformed, X_test_transformed, y_train, y_test)[0].sort_index()\n",
    "            svdmodels.drop(columns = ['Balanced Accuracy', 'Time Taken'], inplace = True)\n",
    "            svdmodels['dims'] = len(svd.components_)\n",
    "            print(\"Success!\")\n",
    "            break\n",
    "\n",
    "\n",
    "    \n",
    "#Compiling Model Results:\n",
    "    print(\"Compiling Model Results\")\n",
    "    models_results = pd.concat([simple_models,\n",
    "                                pcamodels,\n",
    "                                ipcamodels,\n",
    "                                spcamodels,\n",
    "                                ldamodels,\n",
    "                                svdmodels], axis = 1, keys =['Without DR', 'PCA ', 'Incremental-PCA', 'Sparse-PCA', 'LDA', 'SVD'])\n",
    "    \n",
    "    print(\"Pipeline run Successful\")\n",
    "    \n",
    "    return models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc67a3",
   "metadata": {},
   "source": [
    "#### B) Applying pipeline to classification datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bde7b8",
   "metadata": {},
   "source": [
    "#### 1. Marketing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224cda37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-30 00:51:57 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(marketing_df, marketing_classes, test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "914e7364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running LDA\n",
      "Success!\n",
      "9. Running Lazy Predict on LDA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "10. Running SVD\n",
      "Success!\n",
      "11. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 11.5 s (started: 2022-12-29 00:51:12 +05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_classification(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostClassifier', 'BernoulliNB',\n",
    "       'DecisionTreeClassifier', 'KNeighborsClassifier', 'LinearSVC', 'LogisticRegression',\n",
    "       'RandomForestClassifier', 'XGBClassifier']].T       \n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Classification/Marketing.xlsx', sheet_name = 'Marketing Dataset')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe843b",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "442ce3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LDA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dim</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>...</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.85</td>\n",
       "      <td>35</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.83</td>\n",
       "      <td>18</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.84</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>35</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.79</td>\n",
       "      <td>18</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>10</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.79</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.84</td>\n",
       "      <td>35</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.83</td>\n",
       "      <td>18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.81</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.82</td>\n",
       "      <td>35</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83</td>\n",
       "      <td>10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.81</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>35</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.85</td>\n",
       "      <td>18</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.86</td>\n",
       "      <td>35</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.85</td>\n",
       "      <td>18</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.85</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.83</td>\n",
       "      <td>35</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>18</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>10</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.83</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.87</td>\n",
       "      <td>35</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.85</td>\n",
       "      <td>18</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.85</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Without DR                          PCA           \\\n",
       "                         Accuracy ROC AUC F1 Score dim Accuracy ROC AUC   \n",
       "Model                                                                     \n",
       "AdaBoostClassifier           0.87    0.68     0.85  35     0.85    0.63   \n",
       "BernoulliNB                  0.78    0.68     0.79  35     0.84    0.56   \n",
       "DecisionTreeClassifier       0.84    0.70     0.84  35     0.84    0.67   \n",
       "KNeighborsClassifier         0.85    0.61     0.82  35     0.84    0.61   \n",
       "LinearSVC                    0.86    0.65     0.84  35     0.87    0.65   \n",
       "LogisticRegression           0.88    0.68     0.86  35     0.87    0.66   \n",
       "RandomForestClassifier       0.86    0.62     0.83  35     0.86    0.64   \n",
       "XGBClassifier                0.88    0.71     0.87  35     0.87    0.69   \n",
       "\n",
       "                                     Incremental-PCA          ... Sparse-PCA  \\\n",
       "                       F1 Score dims        Accuracy ROC AUC  ...   F1 Score   \n",
       "Model                                                         ...              \n",
       "AdaBoostClassifier         0.83   18            0.87    0.66  ...       0.84   \n",
       "BernoulliNB                0.79   18            0.84    0.58  ...       0.84   \n",
       "DecisionTreeClassifier     0.83   18            0.82    0.65  ...       0.80   \n",
       "KNeighborsClassifier       0.82   18            0.84    0.61  ...       0.83   \n",
       "LinearSVC                  0.85   18            0.88    0.65  ...       0.84   \n",
       "LogisticRegression         0.85   18            0.87    0.66  ...       0.86   \n",
       "RandomForestClassifier     0.83   18            0.86    0.63  ...       0.84   \n",
       "XGBClassifier              0.85   18            0.86    0.66  ...       0.84   \n",
       "\n",
       "                                 LDA                            SVD          \\\n",
       "                       dims Accuracy ROC AUC F1 Score dims Accuracy ROC AUC   \n",
       "Model                                                                         \n",
       "AdaBoostClassifier       10     0.86    0.68     0.85    1     0.86    0.66   \n",
       "BernoulliNB              10     0.83    0.50     0.75    1     0.84    0.55   \n",
       "DecisionTreeClassifier   10     0.83    0.66     0.82    1     0.81    0.64   \n",
       "KNeighborsClassifier     10     0.85    0.66     0.83    1     0.84    0.61   \n",
       "LinearSVC                10     0.87    0.64     0.84    1     0.87    0.65   \n",
       "LogisticRegression       10     0.86    0.64     0.84    1     0.87    0.67   \n",
       "RandomForestClassifier   10     0.83    0.66     0.82    1     0.85    0.63   \n",
       "XGBClassifier            10     0.86    0.65     0.84    1     0.86    0.67   \n",
       "\n",
       "                                      \n",
       "                       F1 Score dims  \n",
       "Model                                 \n",
       "AdaBoostClassifier         0.84   19  \n",
       "BernoulliNB                0.79   19  \n",
       "DecisionTreeClassifier     0.81   19  \n",
       "KNeighborsClassifier       0.81   19  \n",
       "LinearSVC                  0.84   19  \n",
       "LogisticRegression         0.85   19  \n",
       "RandomForestClassifier     0.83   19  \n",
       "XGBClassifier              0.85   19  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2022-12-31 02:39:22 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Classification/Marketing.xlsx', header=[0, 1], index_col=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b94b91",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c23de5",
   "metadata": {},
   "source": [
    "1. For the marketing dataset, initially with full dataset having 35 features gave us the maximum accuracy of 0.88 and F1 score of 0.87 from the XG Boost Algorithm. For Naive bayes, we saw an accuracy of 0.78 and F1 score of 0.79. \n",
    "2. After applying normal PCA, the accuracy and F1 score are almost the same as without applying PCA which means that almost all variation was captured by the Principal Components. Furthermore, Naive Bayes algorithm performance increased greatly when feature reduction was applied as its performance increased from 0.76 to 0.84. However, it is important to note that AUC-ROC of the algorithm dropped.\n",
    "3. Applying the other PCA variants such as Incremental and Sparse PCA does not improve the results and they perform at Par with PCA although sparse PCA reduced the dimensions further to 10 with truly little sacrifice to variance capture. Naive Bayes algorithm's performance increased further as well. However, it is important to note that AUC-ROC of the algorithm dropped.\n",
    "4. Then Linear Discriminant Analysis was tried, and the performance was at Par with the other DR techniques. However, since it reduces the dimensions to 1, it proves to be the best DR technique so far.\n",
    "5. Lastly, Singular Value Decomposition also performed at PAR with the other DR techniques and gave promising results. \n",
    "\n",
    "**From this dataset's perspective LDA performs well since it reduces the dimensions to just 1 with truly little compromise on variance capture.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a02489a",
   "metadata": {},
   "source": [
    "#### 2. Credit Card Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66e6e7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-25 18:35:54 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(credit_df, credit_classes, test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bfdef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:10<00:00,  6.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [02:45<00:00,  5.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:05<00:00,  6.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:26<00:00,  7.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running LDA\n",
      "Success!\n",
      "9. Running Lazy Predict on LDA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [02:36<00:00,  5.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "10. Running SVD\n",
      "Success!\n",
      "11. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:02<00:00,  6.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 18min 9s (started: 2022-12-25 18:35:55 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_classification(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostClassifier', 'BernoulliNB',\n",
    "       'DecisionTreeClassifier', 'KNeighborsClassifier', 'LinearSVC', 'LogisticRegression',\n",
    "       'RandomForestClassifier', 'XGBClassifier']].T       \n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Classification/credit.xlsx', sheet_name = 'Credit Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2b39c",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "13299244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LDA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dim</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Without DR                          PCA           \\\n",
       "                         Accuracy ROC AUC F1 Score dim Accuracy ROC AUC   \n",
       "Model                                                                     \n",
       "AdaBoostClassifier           1.00    0.87     1.00  29     1.00    0.83   \n",
       "BernoulliNB                  1.00    0.83     1.00  29     1.00    0.62   \n",
       "DecisionTreeClassifier       1.00    0.87     1.00  29     1.00    0.87   \n",
       "KNeighborsClassifier         1.00    0.79     1.00  29     1.00    0.87   \n",
       "LinearSVC                    1.00    0.62     1.00  29     1.00    0.71   \n",
       "LogisticRegression           1.00    0.67     1.00  29     1.00    0.67   \n",
       "RandomForestClassifier       1.00    0.83     1.00  29     1.00    0.87   \n",
       "XGBClassifier                1.00    0.83     1.00  29     1.00    0.87   \n",
       "\n",
       "                                     Incremental-PCA                        \\\n",
       "                       F1 Score dims        Accuracy ROC AUC F1 Score dims   \n",
       "Model                                                                        \n",
       "AdaBoostClassifier         1.00   18            1.00    0.83     1.00   19   \n",
       "BernoulliNB                1.00   18            1.00    0.67     1.00   19   \n",
       "DecisionTreeClassifier     1.00   18            1.00    0.87     1.00   19   \n",
       "KNeighborsClassifier       1.00   18            1.00    0.87     1.00   19   \n",
       "LinearSVC                  1.00   18            1.00    0.75     1.00   19   \n",
       "LogisticRegression         1.00   18            1.00    0.67     1.00   19   \n",
       "RandomForestClassifier     1.00   18            1.00    0.83     1.00   19   \n",
       "XGBClassifier              1.00   18            1.00    0.87     1.00   19   \n",
       "\n",
       "                       Sparse-PCA                            LDA          \\\n",
       "                         Accuracy ROC AUC F1 Score dims Accuracy ROC AUC   \n",
       "Model                                                                      \n",
       "AdaBoostClassifier           1.00    0.79     1.00   10     1.00    0.87   \n",
       "BernoulliNB                  1.00    0.50     1.00   10     1.00    0.50   \n",
       "DecisionTreeClassifier       1.00    0.83     1.00   10     1.00    0.87   \n",
       "KNeighborsClassifier         1.00    0.71     1.00   10     1.00    0.83   \n",
       "LinearSVC                    1.00    0.62     1.00   10     1.00    0.79   \n",
       "LogisticRegression           1.00    0.71     1.00   10     1.00    0.79   \n",
       "RandomForestClassifier       1.00    0.79     1.00   10     1.00    0.87   \n",
       "XGBClassifier                1.00    0.79     1.00   10     1.00    0.87   \n",
       "\n",
       "                                          SVD                        \n",
       "                       F1 Score dims Accuracy ROC AUC F1 Score dims  \n",
       "Model                                                                \n",
       "AdaBoostClassifier         1.00    1     1.00    0.83     1.00   19  \n",
       "BernoulliNB                1.00    1     1.00    0.67     1.00   19  \n",
       "DecisionTreeClassifier     1.00    1     1.00    0.83     1.00   19  \n",
       "KNeighborsClassifier       1.00    1     1.00    0.87     1.00   19  \n",
       "LinearSVC                  1.00    1     1.00    0.67     1.00   19  \n",
       "LogisticRegression         1.00    1     1.00    0.71     1.00   19  \n",
       "RandomForestClassifier     1.00    1     1.00    0.83     1.00   19  \n",
       "XGBClassifier              1.00    1     1.00    0.87     1.00   19  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32 ms (started: 2022-12-29 00:58:08 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Classification/credit.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77433dd6",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27853cfa",
   "metadata": {},
   "source": [
    "DR Techniques were tried on Credit Card dataset and the results are summarized below:\n",
    "\n",
    "1. Accuracy and F1-measure of this dataset cannot be compared because it is remarkably close to 1. This is because the dataset is highly imbalanced with 0.15% of fraud classes. Therefore AUC-ROC is a better metric to gauge for this dataset.\n",
    "2. The best AUC-ROC achieved without any DR technique was 0.87 which is kept as a benchmark to compare.\n",
    "3. When normal PCA is applied, some algorithm's AUC-ROC increased such as Support Vector Machine and Random Forest. The best AUC-ROC remained the same at 0.87 which showed PCA to be a good technique capturing all the variance.\n",
    "4. Then, when more PCA variants were tried, the performance was at par for incremental PCA but for Sparse PCA, the AUC-ROC dropped which shows that reducing the dimensions too much to 10 compromises on variance capture.\n",
    "5. However, for LDA on this dataset, the performance was at par with full dataset which makes it the best DR technique as far as it reduced the dimension to 1.\n",
    "6. For SVD, some algorithms suffered dips, but most algorithms performed at par with the without DR which proves it is a good technique as well.\n",
    "\n",
    "**It is evident that LDA has performed good for this dataset as it captures all variance while reducing the total dimensions to 1.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece76ed",
   "metadata": {},
   "source": [
    "#### 3. Heart Disease Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "356f2419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46 ms (started: 2022-12-25 18:55:49 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(heart_df, heart_classes.astype('int'), test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04697970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [04:29<00:00,  9.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [04:24<00:00,  9.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [04:18<00:00,  8.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:32<00:00,  7.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running LDA\n",
      "Success!\n",
      "9. Running Lazy Predict on LDA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [02:58<00:00,  6.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "10. Running SVD\n",
      "Success!\n",
      "11. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [04:25<00:00,  9.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 24min 22s (started: 2022-12-25 18:55:49 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_classification(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostClassifier', 'BernoulliNB',\n",
    "       'DecisionTreeClassifier', 'KNeighborsClassifier', 'LinearSVC', 'LogisticRegression',\n",
    "       'RandomForestClassifier', 'XGBClassifier']].T       \n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Classification/heart.xlsx', sheet_name = 'Heart Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba81c9ce",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "a037f380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LDA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dim</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.89</td>\n",
       "      <td>50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.87</td>\n",
       "      <td>50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.88</td>\n",
       "      <td>28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.88</td>\n",
       "      <td>28</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.89</td>\n",
       "      <td>10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.87</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.86</td>\n",
       "      <td>50</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.87</td>\n",
       "      <td>28</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.87</td>\n",
       "      <td>28</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.87</td>\n",
       "      <td>10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.87</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.89</td>\n",
       "      <td>50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.88</td>\n",
       "      <td>28</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.88</td>\n",
       "      <td>28</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.88</td>\n",
       "      <td>10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.89</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.88</td>\n",
       "      <td>50</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.88</td>\n",
       "      <td>28</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.88</td>\n",
       "      <td>28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.87</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.88</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.88</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.89</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.88</td>\n",
       "      <td>50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.88</td>\n",
       "      <td>28</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.88</td>\n",
       "      <td>28</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.88</td>\n",
       "      <td>10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.88</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.89</td>\n",
       "      <td>10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.89</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Without DR                          PCA           \\\n",
       "                         Accuracy ROC AUC F1 Score dim Accuracy ROC AUC   \n",
       "Model                                                                     \n",
       "AdaBoostClassifier           0.91    0.56     0.89  50     0.91    0.55   \n",
       "BernoulliNB                  0.86    0.70     0.87  50     0.91    0.54   \n",
       "DecisionTreeClassifier       0.86    0.58     0.86  50     0.87    0.59   \n",
       "KNeighborsClassifier         0.90    0.56     0.89  50     0.90    0.56   \n",
       "LinearSVC                    0.92    0.52     0.88  50     0.92    0.52   \n",
       "LogisticRegression           0.92    0.55     0.89  50     0.91    0.55   \n",
       "RandomForestClassifier       0.91    0.55     0.88  50     0.90    0.55   \n",
       "XGBClassifier                0.91    0.55     0.89  50     0.91    0.55   \n",
       "\n",
       "                                     Incremental-PCA                        \\\n",
       "                       F1 Score dims        Accuracy ROC AUC F1 Score dims   \n",
       "Model                                                                        \n",
       "AdaBoostClassifier         0.89   28            0.91    0.55     0.89   28   \n",
       "BernoulliNB                0.88   28            0.91    0.54     0.88   28   \n",
       "DecisionTreeClassifier     0.87   28            0.87    0.60     0.87   28   \n",
       "KNeighborsClassifier       0.88   28            0.90    0.55     0.88   28   \n",
       "LinearSVC                  0.88   28            0.92    0.51     0.88   28   \n",
       "LogisticRegression         0.89   28            0.91    0.55     0.89   28   \n",
       "RandomForestClassifier     0.88   28            0.90    0.55     0.88   28   \n",
       "XGBClassifier              0.89   28            0.91    0.55     0.89   28   \n",
       "\n",
       "                       Sparse-PCA                            LDA          \\\n",
       "                         Accuracy ROC AUC F1 Score dims Accuracy ROC AUC   \n",
       "Model                                                                      \n",
       "AdaBoostClassifier           0.91    0.55     0.89   10     0.92    0.53   \n",
       "BernoulliNB                  0.90    0.58     0.89   10     0.91    0.50   \n",
       "DecisionTreeClassifier       0.87    0.60     0.87   10     0.87    0.58   \n",
       "KNeighborsClassifier         0.90    0.55     0.88   10     0.90    0.55   \n",
       "LinearSVC                    0.91    0.50     0.87   10     0.92    0.52   \n",
       "LogisticRegression           0.91    0.53     0.88   10     0.92    0.56   \n",
       "RandomForestClassifier       0.90    0.56     0.88   10     0.87    0.58   \n",
       "XGBClassifier                0.91    0.54     0.89   10     0.91    0.53   \n",
       "\n",
       "                                          SVD                        \n",
       "                       F1 Score dims Accuracy ROC AUC F1 Score dims  \n",
       "Model                                                                \n",
       "AdaBoostClassifier         0.88    1     0.91    0.55     0.89   31  \n",
       "BernoulliNB                0.87    1     0.88    0.57     0.87   31  \n",
       "DecisionTreeClassifier     0.87    1     0.86    0.58     0.87   31  \n",
       "KNeighborsClassifier       0.88    1     0.91    0.56     0.89   31  \n",
       "LinearSVC                  0.88    1     0.91    0.51     0.88   31  \n",
       "LogisticRegression         0.89    1     0.91    0.54     0.89   31  \n",
       "RandomForestClassifier     0.87    1     0.90    0.55     0.88   31  \n",
       "XGBClassifier              0.88    1     0.91    0.55     0.89   31  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2022-12-29 00:59:21 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Classification/heart.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07dea70",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40e3f3",
   "metadata": {},
   "source": [
    "Since the heart disease dataset is slightly imbalanced, we can use AUC-ROC or F1 score to gauge its performance. I would be making comparison based on both of these. \n",
    "\n",
    "1. Without DR, the best F1-score is achieved to be 0.89 by several algorithms with an AUC-ROC of 0.56. This would be used as a benchmark for further comparisons. \n",
    "2. When PCA is applied, the F1-score and AUC-ROC were still the same as without DR which proved to be a good DR technique as it reduces the dims from 50 to 28.\n",
    "3. Similarly, for other PCA variants, they all performed at PAR however, sparse PCA performs better in a way that it does not compromise on variance capture and reduces dimensions the most which is 10. \n",
    "4. When LDA is applied, there is barely any compromise on variance capture as the metrics remain same however, the dimensions decrease to 1 which is its major achievement.\n",
    "5. SVD performs at par with the other techniques however, the dims are still too high compared to the others.\n",
    "\n",
    "**It is becoming evident that LDA is the winner DR technique!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e696af",
   "metadata": {},
   "source": [
    "#### 4. Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d889cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-25 21:11:50 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetic_df, diabetic_classes.astype('int'), test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2864ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:43<00:00,  7.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:19<00:00,  6.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:19<00:00,  6.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:00<00:00,  6.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running LDA\n",
      "Success!\n",
      "9. Running Lazy Predict on LDA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:03<00:00,  6.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "10. Running SVD\n",
      "Success!\n",
      "11. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:23<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 20min 51s (started: 2022-12-25 21:11:50 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_classification(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostClassifier', 'BernoulliNB',\n",
    "       'DecisionTreeClassifier', 'KNeighborsClassifier', 'LinearSVC', 'LogisticRegression',\n",
    "       'RandomForestClassifier', 'XGBClassifier']].T       \n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Classification/Diabetes.xlsx', sheet_name = 'Diabetes Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b07be",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "06b22bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LDA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dim</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>77</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>30</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>30</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>10</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>77</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>30</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>30</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Without DR                          PCA           \\\n",
       "                         Accuracy ROC AUC F1 Score dim Accuracy ROC AUC   \n",
       "Model                                                                     \n",
       "AdaBoostClassifier           1.00    1.00     1.00  77     1.00    1.00   \n",
       "BernoulliNB                  1.00    1.00     1.00  77     0.96    0.95   \n",
       "DecisionTreeClassifier       1.00    1.00     1.00  77     1.00    1.00   \n",
       "KNeighborsClassifier         0.99    0.99     0.99  77     0.99    0.99   \n",
       "LinearSVC                    1.00    1.00     1.00  77     1.00    1.00   \n",
       "LogisticRegression           1.00    1.00     1.00  77     1.00    1.00   \n",
       "RandomForestClassifier       1.00    1.00     1.00  77     1.00    1.00   \n",
       "XGBClassifier                1.00    1.00     1.00  77     1.00    1.00   \n",
       "\n",
       "                                     Incremental-PCA                        \\\n",
       "                       F1 Score dims        Accuracy ROC AUC F1 Score dims   \n",
       "Model                                                                        \n",
       "AdaBoostClassifier         1.00   30            1.00    1.00     1.00   30   \n",
       "BernoulliNB                0.96   30            0.94    0.90     0.93   30   \n",
       "DecisionTreeClassifier     1.00   30            1.00    0.99     1.00   30   \n",
       "KNeighborsClassifier       0.99   30            0.99    0.99     0.99   30   \n",
       "LinearSVC                  1.00   30            1.00    1.00     1.00   30   \n",
       "LogisticRegression         1.00   30            1.00    1.00     1.00   30   \n",
       "RandomForestClassifier     1.00   30            1.00    1.00     1.00   30   \n",
       "XGBClassifier              1.00   30            1.00    1.00     1.00   30   \n",
       "\n",
       "                       Sparse-PCA                            LDA          \\\n",
       "                         Accuracy ROC AUC F1 Score dims Accuracy ROC AUC   \n",
       "Model                                                                      \n",
       "AdaBoostClassifier           0.99    0.99     0.99   10     1.00    1.00   \n",
       "BernoulliNB                  0.93    0.95     0.94   10     0.81    0.88   \n",
       "DecisionTreeClassifier       0.98    0.98     0.98   10     0.99    0.99   \n",
       "KNeighborsClassifier         0.99    0.99     0.99   10     1.00    1.00   \n",
       "LinearSVC                    0.99    0.99     0.99   10     1.00    1.00   \n",
       "LogisticRegression           0.99    0.99     0.99   10     1.00    1.00   \n",
       "RandomForestClassifier       0.99    0.99     0.99   10     0.99    0.99   \n",
       "XGBClassifier                0.99    0.99     0.99   10     1.00    0.99   \n",
       "\n",
       "                                          SVD                        \n",
       "                       F1 Score dims Accuracy ROC AUC F1 Score dims  \n",
       "Model                                                                \n",
       "AdaBoostClassifier         1.00    1     1.00    1.00     1.00   31  \n",
       "BernoulliNB                0.83    1     0.97    0.94     0.97   31  \n",
       "DecisionTreeClassifier     0.99    1     1.00    1.00     1.00   31  \n",
       "KNeighborsClassifier       1.00    1     0.99    0.99     0.99   31  \n",
       "LinearSVC                  1.00    1     1.00    1.00     1.00   31  \n",
       "LogisticRegression         1.00    1     1.00    1.00     1.00   31  \n",
       "RandomForestClassifier     0.99    1     1.00    1.00     1.00   31  \n",
       "XGBClassifier              1.00    1     1.00    1.00     1.00   31  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-29 00:59:33 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Classification/diabetes.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d7dbc4",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384a181",
   "metadata": {},
   "source": [
    "There cannot be much analysis done on this dataset because all its values are 1 or close to 1 which is too good to be true. It is possible that the sub sample of dataset taken may have very few positive labels which would make it a highly imbalanced dataset and more prone to predicting the same class. But, in any case, it can be noticed that all the DR Techniques perform the same as non-DR one and LDA reduces the dimensions the most, so it still is the winner DR technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff08ed",
   "metadata": {},
   "source": [
    "#### 5. Income Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "547b9602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-25 21:55:31 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(income_df, income_classes.astype('int'), test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cbce5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [02:53<00:00,  5.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [02:58<00:00,  6.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:01<00:00,  6.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [02:48<00:00,  5.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running LDA\n",
      "Success!\n",
      "9. Running Lazy Predict on LDA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [02:17<00:00,  4.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "10. Running SVD\n",
      "Success!\n",
      "11. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:00<00:00,  6.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 17min 4s (started: 2022-12-25 21:55:32 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_classification(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostClassifier', 'BernoulliNB',\n",
    "       'DecisionTreeClassifier', 'KNeighborsClassifier', 'LinearSVC', 'LogisticRegression',\n",
    "       'RandomForestClassifier', 'XGBClassifier']].T       \n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Classification/Income.xlsx', sheet_name = 'Income Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aecf905",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "116cefd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LDA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dim</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "      <td>13</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.71</td>\n",
       "      <td>12</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.70</td>\n",
       "      <td>12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.73</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.70</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>13</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>12</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.64</td>\n",
       "      <td>12</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.64</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "      <td>12</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "      <td>12</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "      <td>13</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "      <td>12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "      <td>12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>13</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>12</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>12</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>13</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>12</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>12</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.78</td>\n",
       "      <td>13</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>12</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "      <td>12</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>13</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "      <td>12</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>12</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Without DR                          PCA           \\\n",
       "                         Accuracy ROC AUC F1 Score dim Accuracy ROC AUC   \n",
       "Model                                                                     \n",
       "AdaBoostClassifier           0.75    0.69     0.74  13     0.72    0.64   \n",
       "BernoulliNB                  0.69    0.63     0.68  13     0.70    0.57   \n",
       "DecisionTreeClassifier       0.75    0.72     0.75  13     0.72    0.68   \n",
       "KNeighborsClassifier         0.74    0.69     0.74  13     0.74    0.69   \n",
       "LinearSVC                    0.69    0.57     0.65  13     0.69    0.57   \n",
       "LogisticRegression           0.69    0.57     0.65  13     0.69    0.57   \n",
       "RandomForestClassifier       0.78    0.75     0.78  13     0.76    0.70   \n",
       "XGBClassifier                0.77    0.73     0.77  13     0.75    0.70   \n",
       "\n",
       "                                     Incremental-PCA                        \\\n",
       "                       F1 Score dims        Accuracy ROC AUC F1 Score dims   \n",
       "Model                                                                        \n",
       "AdaBoostClassifier         0.71   12            0.71    0.63     0.70   12   \n",
       "BernoulliNB                0.65   12            0.69    0.56     0.64   12   \n",
       "DecisionTreeClassifier     0.72   12            0.72    0.68     0.72   12   \n",
       "KNeighborsClassifier       0.74   12            0.74    0.69     0.74   12   \n",
       "LinearSVC                  0.65   12            0.69    0.57     0.65   12   \n",
       "LogisticRegression         0.65   12            0.69    0.57     0.65   12   \n",
       "RandomForestClassifier     0.75   12            0.77    0.71     0.76   12   \n",
       "XGBClassifier              0.74   12            0.76    0.71     0.75   12   \n",
       "\n",
       "                       Sparse-PCA                            LDA          \\\n",
       "                         Accuracy ROC AUC F1 Score dims Accuracy ROC AUC   \n",
       "Model                                                                      \n",
       "AdaBoostClassifier           0.74    0.67     0.73   10     0.72    0.66   \n",
       "BernoulliNB                  0.69    0.62     0.68   10     0.71    0.70   \n",
       "DecisionTreeClassifier       0.73    0.69     0.73   10     0.66    0.61   \n",
       "KNeighborsClassifier         0.74    0.69     0.73   10     0.69    0.63   \n",
       "LinearSVC                    0.69    0.57     0.65   10     0.69    0.57   \n",
       "LogisticRegression           0.69    0.57     0.65   10     0.69    0.57   \n",
       "RandomForestClassifier       0.76    0.72     0.76   10     0.66    0.61   \n",
       "XGBClassifier                0.75    0.71     0.75   10     0.71    0.66   \n",
       "\n",
       "                                          SVD                        \n",
       "                       F1 Score dims Accuracy ROC AUC F1 Score dims  \n",
       "Model                                                                \n",
       "AdaBoostClassifier         0.71    1     0.71    0.63     0.70   12  \n",
       "BernoulliNB                0.72    1     0.69    0.56     0.64   12  \n",
       "DecisionTreeClassifier     0.66    1     0.71    0.67     0.71   12  \n",
       "KNeighborsClassifier       0.69    1     0.73    0.69     0.73   12  \n",
       "LinearSVC                  0.65    1     0.69    0.57     0.65   12  \n",
       "LogisticRegression         0.65    1     0.69    0.57     0.65   12  \n",
       "RandomForestClassifier     0.66    1     0.76    0.70     0.75   12  \n",
       "XGBClassifier              0.71    1     0.74    0.69     0.74   12  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-29 00:59:52 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Classification/income.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573d4b2",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ddbe3",
   "metadata": {},
   "source": [
    "The dataset is not that imbalanced so we can use any of the three metrics to compare the DR techniques. To keep it coherent, lets focus on F1 score for this dataset:\n",
    "\n",
    "1. The best F1 score achieved with full dataset without any DR technique is around 0.78 given by Random Forest.\n",
    "2. After applying PCA, a very slight drop in F1 score is seen however, the dims are not reduced that much either and remain at 12 reduced from 13. So, at the compromise of little variance capture, only 1 feature is reduced.\n",
    "3. Applying different variants of PCA resulted in comparable results. However, sparse PCA performs better in a way that it reduces dimensions from 12 to 10 with truly little compromise on variance capture.\n",
    "4. After applying LDA, the features are reduced to 1 however, there is a significant drop in variance capture which shows that LDA does not perform good on this dataset.\n",
    "5. Lastly, SVD performed like PCA.\n",
    "\n",
    "**It is seen that in this dataset, DR techniques cause a significant decrease in variance capture if features are reduced to less and the conclusion reached from this is that the dataset already contains the most important information.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ba7c7",
   "metadata": {},
   "source": [
    "#### 6. Dry Beans Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "362aa87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-29 01:02:12 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(beans_df, beans_classes.astype('int'), test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "962b367a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:19<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:15<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:14<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:16<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running LDA\n",
      "Success!\n",
      "9. Running Lazy Predict on LDA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:12<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "10. Running SVD\n",
      "Success!\n",
      "11. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:14<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 1min 34s (started: 2022-12-29 01:02:13 +05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_classification(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = results[[]]\n",
    "results = models_results.T[['AdaBoostClassifier', 'BernoulliNB',\n",
    "       'DecisionTreeClassifier', 'KNeighborsClassifier', 'LinearSVC', 'LogisticRegression',\n",
    "       'RandomForestClassifier', 'XGBClassifier']].T       \n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Classification/Beans.xlsx', sheet_name = 'Beans Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1db953",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "a7a515c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LDA</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dim</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>16</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.58</td>\n",
       "      <td>4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.58</td>\n",
       "      <td>4</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>7</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>16</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>10</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>16</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>16</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>16</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>16</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>16</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Without DR                  PCA                 \\\n",
       "                         Accuracy F1 Score dim Accuracy F1 Score dims   \n",
       "Model                                                                   \n",
       "AdaBoostClassifier           0.68     0.62  16     0.44     0.27    4   \n",
       "BernoulliNB                  0.72     0.72  16     0.65     0.58    4   \n",
       "DecisionTreeClassifier       0.89     0.89  16     0.85     0.85    4   \n",
       "KNeighborsClassifier         0.93     0.93  16     0.89     0.89    4   \n",
       "LinearSVC                    0.91     0.91  16     0.85     0.85    4   \n",
       "LogisticRegression           0.92     0.92  16     0.89     0.89    4   \n",
       "RandomForestClassifier       0.92     0.92  16     0.89     0.89    4   \n",
       "XGBClassifier                0.92     0.92  16     0.89     0.89    4   \n",
       "\n",
       "                       Incremental-PCA               Sparse-PCA                \\\n",
       "                              Accuracy F1 Score dims   Accuracy F1 Score dims   \n",
       "Model                                                                           \n",
       "AdaBoostClassifier                0.44     0.27    4       0.74     0.70   10   \n",
       "BernoulliNB                       0.66     0.58    4       0.77     0.76   10   \n",
       "DecisionTreeClassifier            0.85     0.85    4       0.89     0.89   10   \n",
       "KNeighborsClassifier              0.89     0.89    4       0.93     0.93   10   \n",
       "LinearSVC                         0.86     0.85    4       0.91     0.91   10   \n",
       "LogisticRegression                0.89     0.89    4       0.92     0.92   10   \n",
       "RandomForestClassifier            0.89     0.89    4       0.93     0.93   10   \n",
       "XGBClassifier                     0.89     0.89    4       0.92     0.92   10   \n",
       "\n",
       "                            LDA                    SVD                \n",
       "                       Accuracy F1 Score dims Accuracy F1 Score dims  \n",
       "Model                                                                 \n",
       "AdaBoostClassifier         0.73     0.72    7     0.69     0.67    4  \n",
       "BernoulliNB                0.85     0.85    7     0.67     0.64    4  \n",
       "DecisionTreeClassifier     0.89     0.89    7     0.85     0.85    4  \n",
       "KNeighborsClassifier       0.92     0.92    7     0.89     0.89    4  \n",
       "LinearSVC                  0.91     0.91    7     0.86     0.85    4  \n",
       "LogisticRegression         0.92     0.92    7     0.89     0.89    4  \n",
       "RandomForestClassifier     0.93     0.93    7     0.89     0.89    4  \n",
       "XGBClassifier              0.92     0.92    7     0.88     0.88    4  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-29 01:16:14 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Classification/Beans.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d8011f",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ddc477",
   "metadata": {},
   "source": [
    "For the dry bean’s dataset, AUC-ROC was removed since it is a multi-class problem. Since the dataset is balanced, I will be focusing on Accuracy as the metric for comparison.\n",
    "1. The best accuracy achieved for this dataset without any DR technique is 0.92.\n",
    "2. After applying PCA, the accuracy slightly decreased but the dimensions went from 16 to 4 which is good. \n",
    "3. After applying variants of PCA, the accuracy remained at Par with normal PCA. However, sparse PCA gave a slightly better accuracy of 0.93 and reduced features to 10 from 16.\n",
    "4. After applying LDA, the dimensions were reduced to 7 which is exceptionally good with no expense to accuracy and variance capture. LDA proves to be good so far.\n",
    "5. SVD reduced dimensions to 4 but there was a slight drop in accuracy. \n",
    "\n",
    "**LDA still proves to be good as it maintains the best accuracy with significant reduction of features. The other DR techniques are still good enough**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c2704",
   "metadata": {},
   "source": [
    "#### 7. Bank Notes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3023b116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 01:51:27 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(banknotes_df, banknotes_classes.astype('int'), test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d451660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 43.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running LDA\n",
      "Success!\n",
      "9. Running Lazy Predict on LDA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 43.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "10. Running SVD\n",
      "Success!\n",
      "11. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 4.62 s (started: 2022-12-26 01:51:28 +05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_classification(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostClassifier', 'BernoulliNB',\n",
    "       'DecisionTreeClassifier', 'KNeighborsClassifier', 'LinearSVC', 'LogisticRegression',\n",
    "       'RandomForestClassifier', 'XGBClassifier']].T       \n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Classification/BankNotes.xlsx', sheet_name = 'Bank Notes Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ab27f",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7d5ee7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LDA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dim</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>10</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Without DR                          PCA           \\\n",
       "                         Accuracy ROC AUC F1 Score dim Accuracy ROC AUC   \n",
       "Model                                                                     \n",
       "AdaBoostClassifier           0.99    0.99     0.99   4     0.92    0.91   \n",
       "BernoulliNB                  0.86    0.86     0.86   4     0.79    0.77   \n",
       "DecisionTreeClassifier       0.98    0.98     0.98   4     0.95    0.95   \n",
       "KNeighborsClassifier         1.00    1.00     1.00   4     0.97    0.97   \n",
       "LinearSVC                    0.99    0.99     0.99   4     0.92    0.91   \n",
       "LogisticRegression           0.98    0.98     0.98   4     0.92    0.92   \n",
       "RandomForestClassifier       0.99    0.99     0.99   4     0.95    0.95   \n",
       "XGBClassifier                0.99    0.99     0.99   4     0.94    0.95   \n",
       "\n",
       "                                     Incremental-PCA                        \\\n",
       "                       F1 Score dims        Accuracy ROC AUC F1 Score dims   \n",
       "Model                                                                        \n",
       "AdaBoostClassifier         0.92    3            0.93    0.93     0.93    3   \n",
       "BernoulliNB                0.78    3            0.79    0.77     0.78    3   \n",
       "DecisionTreeClassifier     0.95    3            0.94    0.94     0.94    3   \n",
       "KNeighborsClassifier       0.97    3            0.97    0.97     0.97    3   \n",
       "LinearSVC                  0.92    3            0.92    0.92     0.92    3   \n",
       "LogisticRegression         0.92    3            0.92    0.92     0.92    3   \n",
       "RandomForestClassifier     0.95    3            0.95    0.95     0.95    3   \n",
       "XGBClassifier              0.94    3            0.94    0.95     0.94    3   \n",
       "\n",
       "                       Sparse-PCA                            LDA          \\\n",
       "                         Accuracy ROC AUC F1 Score dims Accuracy ROC AUC   \n",
       "Model                                                                      \n",
       "AdaBoostClassifier           0.99    0.99     0.99   10     0.99    0.99   \n",
       "BernoulliNB                  0.86    0.86     0.86   10     0.96    0.97   \n",
       "DecisionTreeClassifier       0.99    0.99     0.99   10     0.99    0.99   \n",
       "KNeighborsClassifier         1.00    1.00     1.00   10     0.98    0.98   \n",
       "LinearSVC                    0.99    0.99     0.99   10     0.98    0.98   \n",
       "LogisticRegression           0.98    0.98     0.98   10     0.98    0.98   \n",
       "RandomForestClassifier       0.99    0.99     0.99   10     0.99    0.99   \n",
       "XGBClassifier                0.99    0.99     0.99   10     0.99    0.99   \n",
       "\n",
       "                                          SVD                        \n",
       "                       F1 Score dims Accuracy ROC AUC F1 Score dims  \n",
       "Model                                                                \n",
       "AdaBoostClassifier         0.99    1     0.95    0.95     0.95    3  \n",
       "BernoulliNB                0.96    1     0.84    0.85     0.84    3  \n",
       "DecisionTreeClassifier     0.99    1     0.97    0.97     0.97    3  \n",
       "KNeighborsClassifier       0.98    1     0.97    0.97     0.97    3  \n",
       "LinearSVC                  0.98    1     0.88    0.89     0.88    3  \n",
       "LogisticRegression         0.98    1     0.89    0.89     0.89    3  \n",
       "RandomForestClassifier     0.99    1     0.97    0.97     0.97    3  \n",
       "XGBClassifier              0.99    1     0.97    0.97     0.97    3  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-29 01:20:27 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Classification/BankNotes.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e215e",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9264e72",
   "metadata": {},
   "source": [
    "This dataset is a banknote authentication dataset. Since the dataset is balanced, we can use accuracy as a metric to gauge it:\n",
    "\n",
    "1. The accuracy achieved without DR techniques is 1 which seems that the model is too good to be true. \n",
    "2. After applying PCA, the accuracy is slightly compromised to 0.97 with just 1 feature reduction.\n",
    "3. Different PCA variants perform similar with sparse PCA performing worse as it increases the dimensions from 4 to 10.\n",
    "4. LDA captures all the variance of the dataset and does not compromise on accuracy while reducing the number of dimensions from 4 to 1 which shows that it performs very well.\n",
    "5. SVD performs at par with PCA.\n",
    "\n",
    "**It can be seen here as well that LDA performs well for this dataset as it reduces number of dimensions to 1 without any compromise in accuracy.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95674b1",
   "metadata": {},
   "source": [
    "#### 8. Audit Risk Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c5dfb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 01:57:13 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(audit_df, audit_classes.astype('int'), test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3680042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 59.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 47.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 46.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 48.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running LDA\n",
      "Success!\n",
      "9. Running Lazy Predict on LDA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 54.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "10. Running SVD\n",
      "Success!\n",
      "11. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 46.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 3.86 s (started: 2022-12-26 01:57:14 +05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_classification(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostClassifier', 'BernoulliNB',\n",
    "       'DecisionTreeClassifier', 'KNeighborsClassifier', 'LinearSVC', 'LogisticRegression',\n",
    "       'RandomForestClassifier', 'XGBClassifier']].T       \n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Classification/AuditRisk.xlsx', sheet_name = 'Audit Risk Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c38a60",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "253d27bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LDA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dim</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>25</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>25</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>25</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>25</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>7</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Without DR                          PCA           \\\n",
       "                         Accuracy ROC AUC F1 Score dim Accuracy ROC AUC   \n",
       "Model                                                                     \n",
       "AdaBoostClassifier           1.00    1.00     1.00  25     0.98    0.98   \n",
       "BernoulliNB                  0.92    0.90     0.92  25     0.87    0.85   \n",
       "DecisionTreeClassifier       1.00    1.00     1.00  25     0.98    0.98   \n",
       "KNeighborsClassifier         0.97    0.96     0.97  25     0.96    0.95   \n",
       "LinearSVC                    0.98    0.98     0.98  25     0.96    0.95   \n",
       "LogisticRegression           0.98    0.98     0.98  25     0.95    0.95   \n",
       "RandomForestClassifier       1.00    1.00     1.00  25     0.98    0.98   \n",
       "XGBClassifier                1.00    1.00     1.00  25     0.97    0.97   \n",
       "\n",
       "                                     Incremental-PCA                        \\\n",
       "                       F1 Score dims        Accuracy ROC AUC F1 Score dims   \n",
       "Model                                                                        \n",
       "AdaBoostClassifier         0.98    7            0.98    0.98     0.98    7   \n",
       "BernoulliNB                0.86    7            0.86    0.84     0.85    7   \n",
       "DecisionTreeClassifier     0.98    7            0.99    0.99     0.99    7   \n",
       "KNeighborsClassifier       0.96    7            0.96    0.95     0.96    7   \n",
       "LinearSVC                  0.96    7            0.95    0.95     0.95    7   \n",
       "LogisticRegression         0.95    7            0.95    0.95     0.95    7   \n",
       "RandomForestClassifier     0.98    7            0.98    0.98     0.98    7   \n",
       "XGBClassifier              0.97    7            0.98    0.98     0.98    7   \n",
       "\n",
       "                       Sparse-PCA                            LDA          \\\n",
       "                         Accuracy ROC AUC F1 Score dims Accuracy ROC AUC   \n",
       "Model                                                                      \n",
       "AdaBoostClassifier           0.99    0.99     0.99   10     0.95    0.94   \n",
       "BernoulliNB                  0.89    0.88     0.89   10     0.95    0.95   \n",
       "DecisionTreeClassifier       0.98    0.98     0.98   10     0.95    0.94   \n",
       "KNeighborsClassifier         0.96    0.95     0.96   10     0.94    0.94   \n",
       "LinearSVC                    0.98    0.98     0.98   10     0.95    0.94   \n",
       "LogisticRegression           0.98    0.98     0.98   10     0.94    0.93   \n",
       "RandomForestClassifier       0.98    0.98     0.98   10     0.95    0.94   \n",
       "XGBClassifier                0.99    0.99     0.99   10     0.95    0.94   \n",
       "\n",
       "                                          SVD                        \n",
       "                       F1 Score dims Accuracy ROC AUC F1 Score dims  \n",
       "Model                                                                \n",
       "AdaBoostClassifier         0.95    1     0.98    0.98     0.98    7  \n",
       "BernoulliNB                0.95    1     0.90    0.90     0.90    7  \n",
       "DecisionTreeClassifier     0.95    1     0.98    0.98     0.98    7  \n",
       "KNeighborsClassifier       0.94    1     0.95    0.95     0.95    7  \n",
       "LinearSVC                  0.95    1     0.96    0.95     0.96    7  \n",
       "LogisticRegression         0.94    1     0.95    0.95     0.95    7  \n",
       "RandomForestClassifier     0.95    1     0.97    0.97     0.97    7  \n",
       "XGBClassifier              0.95    1     0.98    0.98     0.98    7  "
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32 ms (started: 2022-12-29 01:20:48 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Classification/AuditRisk.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17bcb2e",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a45297",
   "metadata": {},
   "source": [
    "The audit risk dataset is a simple dataset therefore it has particularly good metrics. Since the dataset is balanced, I would focus on looking at accuracy for comparison:\n",
    "1. The best accuracy achieved is 1.0 without applying any DR techniques. The total dims are 25.\n",
    "2. After applying PCA, the accuracy slightly decreased to around 0.98 while reducing features significantly to 7 dimensions. \n",
    "3. After trying other PCA variants, the results were at par with PCA with accuracy around 0.99.\n",
    "4. After applying LDA, the best accuracy achieved was 0.95 which is slightly less than 1 however the number of dimensions become 1 which is a significant achievement.\n",
    "5. SVD gives an accuracy of 0.98 and reduces dimensions to 7 which is the same  as PCA.\n",
    "\n",
    "**All techniques perform quite well on this dataset. LDA compromises slightly on variance capture however it reduces dimensionality the most.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2a81a",
   "metadata": {},
   "source": [
    "## 5.3 Regression Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103b0b5",
   "metadata": {},
   "source": [
    "### 5.3.1 Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "31d5beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Combined Power Plant dataframe is:  (9568, 5)\n",
      "Shape of Energy Efficiency dataframe is:  (768, 10)\n",
      "Shape of Aquatic Toxicity dataframe is:  (546, 8)\n",
      "Shape of Seoul bike dataframe is:  (8760, 13)\n",
      "Shape of Red Wine Quality dataframe is:  (1599, 12)\n",
      "Shape of student dataframe is:  (649, 33)\n",
      "Shape of Toms Hardware dataframe is:  (28179, 97)\n",
      "time: 281 ms (started: 2022-12-26 16:14:57 +05:00)\n"
     ]
    }
   ],
   "source": [
    "power_df = pd.read_csv('Regression/CombinedCyclePowerPlantUCI.csv')  #Combined Cycle Power Plant dataset\n",
    "energy_df = pd.read_excel('Regression/EnergyEfficiencyUCI.xlsx')  #Energy Efficiency Dataset\n",
    "aquatic_df = pd.read_csv('Regression/qsar_aquatic_toxicityUCI.csv', sep = ';', names = ['TPSA', 'SAacc', 'H-050', 'MLOGP'\n",
    "                                                                                       'RDCHI', 'GATS1p','nN','C-040', \n",
    "                                                                                        'quantitative response_LC50']) #Aquatic Toxicity Dataset\n",
    "bikes_df = pd.read_csv('Regression/SeoulBikeDataUCI.csv', encoding= 'unicode_escape')  #Bike Sharing Dataset\n",
    "redwine_df = pd.read_csv('Regression/RedWineQualityUCI.csv', sep = ';')  #Red Wine Quality Dataset\n",
    "student_df = pd.read_csv('Regression/student-porUCI.csv', sep = ';')  #Student Performance dataset\n",
    "hardware_df = pd.read_csv('Regression/TomsHardwareUCI.data', names = ['NCD_0', 'NCD_1', 'NCD_2', 'NCD_3', 'NCD_4', 'NCD_5', 'NCD_6', 'NCD_7',\n",
    "                                                                    'BL_0', 'BL_1', 'BL_2', 'BL_3', 'BL_4', 'BL_5', 'BL_6', 'BL_7',\n",
    "                                                                    'NAD_0', 'NAD_1', 'NAD_2', 'NAD_3', 'NAD_4', 'NAD_5', 'NAD_6', 'NAD_7',\n",
    "                                                                    'AI_0', 'AI_1', 'AI_2', 'AI_3', 'AI_4', 'AI_5', 'AI_6', 'AI_7', 'AI_8',\n",
    "                                                                    'NAC_0', 'NAC_1', 'NAC_2', 'NAC_3', 'NAC_4', 'NAC_5', 'NAC_6', 'NAC_7',\n",
    "                                                                    'ND_0', 'ND_1', 'ND_2', 'ND_3', 'ND_4', 'ND_5', 'ND_6', 'ND_7',\n",
    "                                                                    'CS_0', 'CS_1', 'CS_2', 'CS_3', 'CS_4', 'CS_5', 'CS_6', 'CS_7',\n",
    "                                                                    'AT_0', 'AT_1', 'AT_2', 'AT_3', 'AT_4', 'AT_5', 'AT_6', 'AT_7',\n",
    "                                                                    'NA_0', 'NA_1', 'NA_2', 'NA_3', 'NA_4', 'NA_5', 'NA_6', 'NA_7',\n",
    "                                                                    'ADL_0', 'ADL_1', 'ADL_2', 'ADL_3', 'ADL_4', 'ADL_5', 'ADL_6', 'ADL_7',\n",
    "                                                                    'AS(NA)_0', 'AS(NA)_1', 'AS(NA)_2', 'AS(NA)_3', 'AS(NA)_4', 'AS(NA)_5', 'AS(NA)_6', 'AS(NA)_7',\n",
    "                                                                    'AS(NAC)_0', 'AS(NAC)_1', 'AS(NAC)_2', 'AS(NAC)_3', 'AS(NAC)_4', 'AS(NAC)_5', 'AS(NAC)_6', 'AS(NAC)_7'\n",
    "                                                                    ])   #Tom's Hardware Dataset\n",
    "\n",
    "\n",
    "print('Shape of Combined Power Plant dataframe is: ', power_df.shape)\n",
    "print('Shape of Energy Efficiency dataframe is: ', energy_df.shape)\n",
    "print('Shape of Aquatic Toxicity dataframe is: ', aquatic_df.shape)\n",
    "print('Shape of Seoul bike dataframe is: ', bikes_df.shape)\n",
    "print('Shape of Red Wine Quality dataframe is: ', redwine_df.shape)\n",
    "print('Shape of student dataframe is: ', student_df.shape)\n",
    "print('Shape of Toms Hardware dataframe is: ', hardware_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bbabc7",
   "metadata": {},
   "source": [
    "### 5.3.2 Pre-Processing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bddafc0",
   "metadata": {},
   "source": [
    "#### 1. Power Consumption Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "75bb08ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT    0\n",
      "V     0\n",
      "AP    0\n",
      "RH    0\n",
      "PE    0\n",
      "dtype: int64\n",
      "AT    float64\n",
      "V     float64\n",
      "AP    float64\n",
      "RH    float64\n",
      "PE    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.34</td>\n",
       "      <td>40.77</td>\n",
       "      <td>1010.84</td>\n",
       "      <td>90.01</td>\n",
       "      <td>480.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.64</td>\n",
       "      <td>58.49</td>\n",
       "      <td>1011.40</td>\n",
       "      <td>74.20</td>\n",
       "      <td>445.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.74</td>\n",
       "      <td>56.90</td>\n",
       "      <td>1007.15</td>\n",
       "      <td>41.91</td>\n",
       "      <td>438.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.07</td>\n",
       "      <td>49.69</td>\n",
       "      <td>1007.22</td>\n",
       "      <td>76.79</td>\n",
       "      <td>453.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.80</td>\n",
       "      <td>40.66</td>\n",
       "      <td>1017.13</td>\n",
       "      <td>97.20</td>\n",
       "      <td>464.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AT     V      AP    RH     PE\n",
       "0  8.34 40.77 1010.84 90.01 480.48\n",
       "1 23.64 58.49 1011.40 74.20 445.75\n",
       "2 29.74 56.90 1007.15 41.91 438.76\n",
       "3 19.07 49.69 1007.22 76.79 453.09\n",
       "4 11.80 40.66 1017.13 97.20 464.43"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 15:55:54 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(power_df.isnull().sum()) #Check missing values\n",
    "print(power_df.dtypes)   #Check data types\n",
    "power_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "06461d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (9568, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AT    V   AP   RH\n",
       "0 0.18 0.27 0.44 0.86\n",
       "1 0.62 0.59 0.46 0.65\n",
       "2 0.79 0.56 0.35 0.22\n",
       "3 0.49 0.43 0.35 0.69\n",
       "4 0.28 0.27 0.60 0.96"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-26 15:55:55 +05:00)\n"
     ]
    }
   ],
   "source": [
    "power_classes = power_df[['PE']]\n",
    "power_df.drop(columns = ['PE'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#Scaling and One-hot encoding\n",
    "Scaler = MinMaxScaler()\n",
    "power_df = pd.get_dummies(power_df)\n",
    "power_df = pd.DataFrame(Scaler.fit_transform(power_df), columns = power_df.columns)\n",
    "print('Shape of df now is: ', power_df.shape)\n",
    "power_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277271bf",
   "metadata": {},
   "source": [
    "#### 2. Energy Efficiency Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "21d7ca9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1    0\n",
      "X2    0\n",
      "X3    0\n",
      "X4    0\n",
      "X5    0\n",
      "X6    0\n",
      "X7    0\n",
      "X8    0\n",
      "Y1    0\n",
      "Y2    0\n",
      "dtype: int64\n",
      "X1    float64\n",
      "X2    float64\n",
      "X3    float64\n",
      "X4    float64\n",
      "X5    float64\n",
      "X6      int64\n",
      "X7    float64\n",
      "X8      int64\n",
      "Y1    float64\n",
      "Y2    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.50</td>\n",
       "      <td>294.00</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.50</td>\n",
       "      <td>294.00</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.50</td>\n",
       "      <td>294.00</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.50</td>\n",
       "      <td>294.00</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.50</td>\n",
       "      <td>318.50</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1     X2     X3     X4   X5  X6   X7  X8    Y1    Y2\n",
       "0 0.98 514.50 294.00 110.25 7.00   2 0.00   0 15.55 21.33\n",
       "1 0.98 514.50 294.00 110.25 7.00   3 0.00   0 15.55 21.33\n",
       "2 0.98 514.50 294.00 110.25 7.00   4 0.00   0 15.55 21.33\n",
       "3 0.98 514.50 294.00 110.25 7.00   5 0.00   0 15.55 21.33\n",
       "4 0.90 563.50 318.50 122.50 7.00   2 0.00   0 20.84 28.28"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-26 15:55:56 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(energy_df.isnull().sum()) #Check missing values\n",
    "print(energy_df.dtypes)   #Check data types\n",
    "energy_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0de05422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (768, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2   X3   X4   X5   X6   X7   X8\n",
       "0 1.00 0.00 0.29 0.00 1.00 0.00 0.00 0.00\n",
       "1 1.00 0.00 0.29 0.00 1.00 0.33 0.00 0.00\n",
       "2 1.00 0.00 0.29 0.00 1.00 0.67 0.00 0.00\n",
       "3 1.00 0.00 0.29 0.00 1.00 1.00 0.00 0.00\n",
       "4 0.78 0.17 0.43 0.11 1.00 0.00 0.00 0.00"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-26 15:55:56 +05:00)\n"
     ]
    }
   ],
   "source": [
    "energy_classes = energy_df[['Y1']]\n",
    "energy_df.drop(columns = ['Y1', 'Y2'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#Scaling and One-hot encoding\n",
    "Scaler = MinMaxScaler()\n",
    "energy_df = pd.get_dummies(energy_df)\n",
    "energy_df = pd.DataFrame(Scaler.fit_transform(energy_df), columns = energy_df.columns)\n",
    "print('Shape of df now is: ', energy_df.shape)\n",
    "energy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920401b1",
   "metadata": {},
   "source": [
    "#### 3. Aquatic Toxicity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e80db273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPSA                          0\n",
      "SAacc                         0\n",
      "H-050                         0\n",
      "MLOGPRDCHI                    0\n",
      "GATS1p                        0\n",
      "nN                            0\n",
      "C-040                         0\n",
      "quantitative response_LC50    0\n",
      "dtype: int64\n",
      "TPSA                          float64\n",
      "SAacc                           int64\n",
      "H-050                         float64\n",
      "MLOGPRDCHI                    float64\n",
      "GATS1p                        float64\n",
      "nN                              int64\n",
      "C-040                           int64\n",
      "quantitative response_LC50    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPSA</th>\n",
       "      <th>SAacc</th>\n",
       "      <th>H-050</th>\n",
       "      <th>MLOGPRDCHI</th>\n",
       "      <th>GATS1p</th>\n",
       "      <th>nN</th>\n",
       "      <th>C-040</th>\n",
       "      <th>quantitative response_LC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.23</th>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.23</th>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.45</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.23</th>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TPSA  SAacc  H-050  MLOGPRDCHI  GATS1p  nN  C-040  \\\n",
       "0.00  0.00      0   2.42        1.23    0.67   0      0   \n",
       "0.00  0.00      0   2.64        1.40    0.63   0      0   \n",
       "9.23 11.00      0   5.80        2.93    0.49   0      0   \n",
       "9.23 11.00      0   5.45        2.89    0.49   0      0   \n",
       "9.23 11.00      0   4.07        2.76    0.69   0      0   \n",
       "\n",
       "      quantitative response_LC50  \n",
       "0.00                        3.74  \n",
       "0.00                        4.33  \n",
       "9.23                        7.02  \n",
       "9.23                        6.72  \n",
       "9.23                        5.98  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-26 15:56:12 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(aquatic_df.isnull().sum()) #Check missing values\n",
    "print(aquatic_df.dtypes)   #Check data types\n",
    "aquatic_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "9b8899a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (546, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPSA</th>\n",
       "      <th>SAacc</th>\n",
       "      <th>H-050</th>\n",
       "      <th>MLOGPRDCHI</th>\n",
       "      <th>GATS1p</th>\n",
       "      <th>nN</th>\n",
       "      <th>C-040</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TPSA  SAacc  H-050  MLOGPRDCHI  GATS1p   nN  C-040\n",
       "0  0.00   0.00   0.57        0.04    0.17 0.00   0.00\n",
       "1  0.00   0.00   0.58        0.07    0.16 0.00   0.00\n",
       "2  0.02   0.00   0.79        0.35    0.09 0.00   0.00\n",
       "3  0.02   0.00   0.76        0.35    0.10 0.00   0.00\n",
       "4  0.02   0.00   0.67        0.32    0.19 0.00   0.00"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 15:56:43 +05:00)\n"
     ]
    }
   ],
   "source": [
    "aquatic_classes = aquatic_df[['quantitative response_LC50']]\n",
    "aquatic_df.drop(columns = ['quantitative response_LC50'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#Scaling and One-hot encoding\n",
    "Scaler = MinMaxScaler()\n",
    "aquatic_df = pd.get_dummies(aquatic_df)\n",
    "aquatic_df = pd.DataFrame(Scaler.fit_transform(aquatic_df), columns = aquatic_df.columns)\n",
    "print('Shape of df now is: ', aquatic_df.shape)\n",
    "aquatic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634c7c4c",
   "metadata": {},
   "source": [
    "#### 4. Seoul Bikes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d214e5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rented Bike Count            0\n",
      "Hour                         0\n",
      "Temperature(°C)              0\n",
      "Humidity(%)                  0\n",
      "Wind speed (m/s)             0\n",
      "Visibility (10m)             0\n",
      "Dew point temperature(°C)    0\n",
      "Solar Radiation (MJ/m2)      0\n",
      "Rainfall(mm)                 0\n",
      "Snowfall (cm)                0\n",
      "Seasons                      0\n",
      "Holiday                      0\n",
      "Functioning Day              0\n",
      "dtype: int64\n",
      "Rented Bike Count              int64\n",
      "Hour                           int64\n",
      "Temperature(°C)              float64\n",
      "Humidity(%)                    int64\n",
      "Wind speed (m/s)             float64\n",
      "Visibility (10m)               int64\n",
      "Dew point temperature(°C)    float64\n",
      "Solar Radiation (MJ/m2)      float64\n",
      "Rainfall(mm)                 float64\n",
      "Snowfall (cm)                float64\n",
      "Seasons                       object\n",
      "Holiday                       object\n",
      "Functioning Day               object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.20</td>\n",
       "      <td>37</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>38</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>39</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>36</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2000</td>\n",
       "      <td>-18.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "0                254     0            -5.20           37              2.20   \n",
       "1                204     1            -5.50           38              0.80   \n",
       "2                173     2            -6.00           39              1.00   \n",
       "3                107     3            -6.20           40              0.90   \n",
       "4                 78     4            -6.00           36              2.30   \n",
       "\n",
       "   Visibility (10m)  Dew point temperature(°C)  Solar Radiation (MJ/m2)  \\\n",
       "0              2000                     -17.60                     0.00   \n",
       "1              2000                     -17.60                     0.00   \n",
       "2              2000                     -17.70                     0.00   \n",
       "3              2000                     -17.60                     0.00   \n",
       "4              2000                     -18.60                     0.00   \n",
       "\n",
       "   Rainfall(mm)  Snowfall (cm) Seasons     Holiday Functioning Day  \n",
       "0          0.00           0.00  Winter  No Holiday             Yes  \n",
       "1          0.00           0.00  Winter  No Holiday             Yes  \n",
       "2          0.00           0.00  Winter  No Holiday             Yes  \n",
       "3          0.00           0.00  Winter  No Holiday             Yes  \n",
       "4          0.00           0.00  Winter  No Holiday             Yes  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-26 03:34:54 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(bikes_df.isnull().sum()) #Check missing values\n",
    "print(bikes_df.dtypes)   #Check data types\n",
    "bikes_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "461dfde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (8760, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Seasons_Autumn</th>\n",
       "      <th>Seasons_Spring</th>\n",
       "      <th>Seasons_Summer</th>\n",
       "      <th>Seasons_Winter</th>\n",
       "      <th>Holiday_Holiday</th>\n",
       "      <th>Holiday_No Holiday</th>\n",
       "      <th>Functioning Day_No</th>\n",
       "      <th>Functioning Day_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  Visibility (10m)  \\\n",
       "0  0.00             0.22         0.38              0.30              1.00   \n",
       "1  0.04             0.22         0.39              0.11              1.00   \n",
       "2  0.09             0.21         0.40              0.14              1.00   \n",
       "3  0.13             0.20         0.41              0.12              1.00   \n",
       "4  0.17             0.21         0.37              0.31              1.00   \n",
       "\n",
       "   Dew point temperature(°C)  Solar Radiation (MJ/m2)  Rainfall(mm)  \\\n",
       "0                       0.22                     0.00          0.00   \n",
       "1                       0.22                     0.00          0.00   \n",
       "2                       0.22                     0.00          0.00   \n",
       "3                       0.22                     0.00          0.00   \n",
       "4                       0.21                     0.00          0.00   \n",
       "\n",
       "   Snowfall (cm)  Seasons_Autumn  Seasons_Spring  Seasons_Summer  \\\n",
       "0           0.00            0.00            0.00            0.00   \n",
       "1           0.00            0.00            0.00            0.00   \n",
       "2           0.00            0.00            0.00            0.00   \n",
       "3           0.00            0.00            0.00            0.00   \n",
       "4           0.00            0.00            0.00            0.00   \n",
       "\n",
       "   Seasons_Winter  Holiday_Holiday  Holiday_No Holiday  Functioning Day_No  \\\n",
       "0            1.00             0.00                1.00                0.00   \n",
       "1            1.00             0.00                1.00                0.00   \n",
       "2            1.00             0.00                1.00                0.00   \n",
       "3            1.00             0.00                1.00                0.00   \n",
       "4            1.00             0.00                1.00                0.00   \n",
       "\n",
       "   Functioning Day_Yes  \n",
       "0                 1.00  \n",
       "1                 1.00  \n",
       "2                 1.00  \n",
       "3                 1.00  \n",
       "4                 1.00  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-26 03:34:54 +05:00)\n"
     ]
    }
   ],
   "source": [
    "bikes_classes = bikes_df[['Rented Bike Count']]\n",
    "bikes_df.drop(columns = ['Rented Bike Count'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#Scaling and One-hot encoding\n",
    "Scaler = MinMaxScaler()\n",
    "bikes_df = pd.get_dummies(bikes_df)\n",
    "bikes_df = pd.DataFrame(Scaler.fit_transform(bikes_df), columns = bikes_df.columns)\n",
    "print('Shape of df now is: ', bikes_df.shape)\n",
    "bikes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70e6a5",
   "metadata": {},
   "source": [
    "#### 5. Red Wine Quality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "464bbe4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n",
      "fixed acidity           float64\n",
      "volatile acidity        float64\n",
      "citric acid             float64\n",
      "residual sugar          float64\n",
      "chlorides               float64\n",
      "free sulfur dioxide     float64\n",
      "total sulfur dioxide    float64\n",
      "density                 float64\n",
      "pH                      float64\n",
      "sulphates               float64\n",
      "alcohol                 float64\n",
      "quality                   int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.08</td>\n",
       "      <td>11.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>25.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.80</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.80</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.20</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.07</td>\n",
       "      <td>17.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.80</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.08</td>\n",
       "      <td>11.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           7.40              0.70         0.00            1.90       0.08   \n",
       "1           7.80              0.88         0.00            2.60       0.10   \n",
       "2           7.80              0.76         0.04            2.30       0.09   \n",
       "3          11.20              0.28         0.56            1.90       0.07   \n",
       "4           7.40              0.70         0.00            1.90       0.08   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density   pH  sulphates  \\\n",
       "0                11.00                 34.00     1.00 3.51       0.56   \n",
       "1                25.00                 67.00     1.00 3.20       0.68   \n",
       "2                15.00                 54.00     1.00 3.26       0.65   \n",
       "3                17.00                 60.00     1.00 3.16       0.58   \n",
       "4                11.00                 34.00     1.00 3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0     9.40        5  \n",
       "1     9.80        5  \n",
       "2     9.80        5  \n",
       "3     9.80        6  \n",
       "4     9.40        5  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 03:34:54 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(redwine_df.isnull().sum()) #Check missing values\n",
    "print(redwine_df.dtypes)   #Check data types\n",
    "redwine_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "261e340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (1599, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           0.25              0.40         0.00            0.07       0.11   \n",
       "1           0.28              0.52         0.00            0.12       0.14   \n",
       "2           0.28              0.44         0.04            0.10       0.13   \n",
       "3           0.58              0.11         0.56            0.07       0.11   \n",
       "4           0.25              0.40         0.00            0.07       0.11   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density   pH  sulphates  alcohol  \n",
       "0                 0.14                  0.10     0.57 0.61       0.14     0.15  \n",
       "1                 0.34                  0.22     0.49 0.36       0.21     0.22  \n",
       "2                 0.20                  0.17     0.51 0.41       0.19     0.22  \n",
       "3                 0.23                  0.19     0.58 0.33       0.15     0.22  \n",
       "4                 0.14                  0.10     0.57 0.61       0.14     0.15  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-26 03:34:55 +05:00)\n"
     ]
    }
   ],
   "source": [
    "redwine_classes = redwine_df[['quality']]\n",
    "redwine_df.drop(columns = ['quality'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#Scaling and One-hot encoding\n",
    "Scaler = MinMaxScaler()\n",
    "redwine_df = pd.get_dummies(redwine_df)\n",
    "redwine_df = pd.DataFrame(Scaler.fit_transform(redwine_df), columns = redwine_df.columns)\n",
    "print('Shape of df now is: ', redwine_df.shape)\n",
    "redwine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebebb638",
   "metadata": {},
   "source": [
    "#### 6. Student Portugese Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "cbab31ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school        0\n",
      "sex           0\n",
      "age           0\n",
      "address       0\n",
      "famsize       0\n",
      "Pstatus       0\n",
      "Medu          0\n",
      "Fedu          0\n",
      "Mjob          0\n",
      "Fjob          0\n",
      "reason        0\n",
      "guardian      0\n",
      "traveltime    0\n",
      "studytime     0\n",
      "failures      0\n",
      "schoolsup     0\n",
      "famsup        0\n",
      "paid          0\n",
      "activities    0\n",
      "nursery       0\n",
      "higher        0\n",
      "internet      0\n",
      "romantic      0\n",
      "famrel        0\n",
      "freetime      0\n",
      "goout         0\n",
      "Dalc          0\n",
      "Walc          0\n",
      "health        0\n",
      "absences      0\n",
      "G1            0\n",
      "G2            0\n",
      "G3            0\n",
      "dtype: int64\n",
      "school        object\n",
      "sex           object\n",
      "age            int64\n",
      "address       object\n",
      "famsize       object\n",
      "Pstatus       object\n",
      "Medu           int64\n",
      "Fedu           int64\n",
      "Mjob          object\n",
      "Fjob          object\n",
      "reason        object\n",
      "guardian      object\n",
      "traveltime     int64\n",
      "studytime      int64\n",
      "failures       int64\n",
      "schoolsup     object\n",
      "famsup        object\n",
      "paid          object\n",
      "activities    object\n",
      "nursery       object\n",
      "higher        object\n",
      "internet      object\n",
      "romantic      object\n",
      "famrel         int64\n",
      "freetime       int64\n",
      "goout          int64\n",
      "Dalc           int64\n",
      "Walc           int64\n",
      "health         int64\n",
      "absences       int64\n",
      "G1             int64\n",
      "G2             int64\n",
      "G3             int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        4   0  11  11  \n",
       "1      5        3      3     1     1      3        2   9  11  11  \n",
       "2      4        3      2     2     3      3        6  12  13  12  \n",
       "3      3        2      2     1     1      5        0  14  14  14  \n",
       "4      4        3      2     1     2      5        0  11  13  13  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 16:15:05 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(student_df.isnull().sum()) #Check missing values\n",
    "print(student_df.dtypes)   #Check data types\n",
    "student_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "cf3e6653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (649, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>...</th>\n",
       "      <th>activities_no</th>\n",
       "      <th>activities_yes</th>\n",
       "      <th>nursery_no</th>\n",
       "      <th>nursery_yes</th>\n",
       "      <th>higher_no</th>\n",
       "      <th>higher_yes</th>\n",
       "      <th>internet_no</th>\n",
       "      <th>internet_yes</th>\n",
       "      <th>romantic_no</th>\n",
       "      <th>romantic_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.43</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0 0.43  1.00  1.00        0.33       0.33      0.00    0.75      0.50   0.75   \n",
       "1 0.29  0.25  0.25        0.00       0.33      0.00    1.00      0.50   0.50   \n",
       "2 0.00  0.25  0.25        0.00       0.33      0.00    0.75      0.50   0.25   \n",
       "3 0.00  1.00  0.50        0.00       0.67      0.00    0.50      0.25   0.25   \n",
       "4 0.14  0.75  0.75        0.00       0.33      0.00    0.75      0.50   0.25   \n",
       "\n",
       "   Dalc  ...  activities_no  activities_yes  nursery_no  nursery_yes  \\\n",
       "0  0.00  ...           1.00            0.00        0.00         1.00   \n",
       "1  0.00  ...           1.00            0.00        1.00         0.00   \n",
       "2  0.25  ...           1.00            0.00        0.00         1.00   \n",
       "3  0.00  ...           0.00            1.00        0.00         1.00   \n",
       "4  0.00  ...           1.00            0.00        0.00         1.00   \n",
       "\n",
       "   higher_no  higher_yes  internet_no  internet_yes  romantic_no  romantic_yes  \n",
       "0       0.00        1.00         1.00          0.00         1.00          0.00  \n",
       "1       0.00        1.00         0.00          1.00         1.00          0.00  \n",
       "2       0.00        1.00         0.00          1.00         1.00          0.00  \n",
       "3       0.00        1.00         0.00          1.00         0.00          1.00  \n",
       "4       0.00        1.00         1.00          0.00         1.00          0.00  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-26 16:15:14 +05:00)\n"
     ]
    }
   ],
   "source": [
    "student_classes = student_df[['G3']]\n",
    "student_df.drop(columns = [ 'G3'], inplace = True)  #Dropping unnecessary columns\n",
    "Scaler = MinMaxScaler()\n",
    "\n",
    "#Scaling and One-hot encoding\n",
    "student_df = pd.get_dummies(student_df)\n",
    "student_df = pd.DataFrame(Scaler.fit_transform(student_df), columns = student_df.columns)\n",
    "print('Shape of df now is: ', student_df.shape)\n",
    "student_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d0ab4",
   "metadata": {},
   "source": [
    "#### 7. Tom's Hardware Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "11b7772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCD_0        0\n",
      "NCD_1        0\n",
      "NCD_2        0\n",
      "NCD_3        0\n",
      "NCD_4        0\n",
      "            ..\n",
      "AS(NAC)_3    0\n",
      "AS(NAC)_4    0\n",
      "AS(NAC)_5    0\n",
      "AS(NAC)_6    0\n",
      "AS(NAC)_7    0\n",
      "Length: 97, dtype: int64\n",
      "NCD_0          int64\n",
      "NCD_1          int64\n",
      "NCD_2          int64\n",
      "NCD_3          int64\n",
      "NCD_4          int64\n",
      "              ...   \n",
      "AS(NAC)_3    float64\n",
      "AS(NAC)_4    float64\n",
      "AS(NAC)_5    float64\n",
      "AS(NAC)_6    float64\n",
      "AS(NAC)_7    float64\n",
      "Length: 97, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCD_0</th>\n",
       "      <th>NCD_1</th>\n",
       "      <th>NCD_2</th>\n",
       "      <th>NCD_3</th>\n",
       "      <th>NCD_4</th>\n",
       "      <th>NCD_5</th>\n",
       "      <th>NCD_6</th>\n",
       "      <th>NCD_7</th>\n",
       "      <th>BL_0</th>\n",
       "      <th>BL_1</th>\n",
       "      <th>...</th>\n",
       "      <th>AS(NA)_6</th>\n",
       "      <th>AS(NA)_7</th>\n",
       "      <th>AS(NAC)_0</th>\n",
       "      <th>AS(NAC)_1</th>\n",
       "      <th>AS(NAC)_2</th>\n",
       "      <th>AS(NAC)_3</th>\n",
       "      <th>AS(NAC)_4</th>\n",
       "      <th>AS(NAC)_5</th>\n",
       "      <th>AS(NAC)_6</th>\n",
       "      <th>AS(NAC)_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NCD_0  NCD_1  NCD_2  NCD_3  NCD_4  NCD_5  NCD_6  NCD_7  BL_0  BL_1  ...  \\\n",
       "0      0      0      0      0      0      0      0      0  0.00  0.00  ...   \n",
       "1      0      0      0      0      0      0      0      0  0.00  0.00  ...   \n",
       "2      0      0      0      0      0      0      0      0  0.00  0.00  ...   \n",
       "3      0      0      0      0      0      0      0      0  0.00  0.00  ...   \n",
       "4      0      0      0      0      0      0      0      0  0.00  0.00  ...   \n",
       "\n",
       "   AS(NA)_6  AS(NA)_7  AS(NAC)_0  AS(NAC)_1  AS(NAC)_2  AS(NAC)_3  AS(NAC)_4  \\\n",
       "0      0.00      0.00       0.00       0.00       0.00       0.00       0.00   \n",
       "1      0.00      0.00       0.00       0.00       0.00       0.00       0.00   \n",
       "2      0.00      0.00       0.00       0.00       0.00       0.00       0.00   \n",
       "3      0.00      0.00       0.00       0.00       0.00       0.00       0.00   \n",
       "4      0.00      0.00       0.00       0.00       0.00       0.00       0.00   \n",
       "\n",
       "   AS(NAC)_5  AS(NAC)_6  AS(NAC)_7  \n",
       "0       0.00       0.00       4.50  \n",
       "1       0.00       0.00       3.50  \n",
       "2       0.00       0.00       2.00  \n",
       "3       0.00       0.00       2.00  \n",
       "4       0.00       0.00       1.50  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-26 03:34:58 +05:00)\n"
     ]
    }
   ],
   "source": [
    "print(hardware_df.isnull().sum()) #Check missing values\n",
    "print(hardware_df.dtypes)   #Check data types\n",
    "hardware_df.head()  #Bird's eye view of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fc4ed5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df now is:  (28179, 96)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCD_0</th>\n",
       "      <th>NCD_1</th>\n",
       "      <th>NCD_2</th>\n",
       "      <th>NCD_3</th>\n",
       "      <th>NCD_4</th>\n",
       "      <th>NCD_5</th>\n",
       "      <th>NCD_6</th>\n",
       "      <th>NCD_7</th>\n",
       "      <th>BL_0</th>\n",
       "      <th>BL_1</th>\n",
       "      <th>...</th>\n",
       "      <th>AS(NA)_5</th>\n",
       "      <th>AS(NA)_6</th>\n",
       "      <th>AS(NA)_7</th>\n",
       "      <th>AS(NAC)_0</th>\n",
       "      <th>AS(NAC)_1</th>\n",
       "      <th>AS(NAC)_2</th>\n",
       "      <th>AS(NAC)_3</th>\n",
       "      <th>AS(NAC)_4</th>\n",
       "      <th>AS(NAC)_5</th>\n",
       "      <th>AS(NAC)_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NCD_0  NCD_1  NCD_2  NCD_3  NCD_4  NCD_5  NCD_6  NCD_7  BL_0  BL_1  ...  \\\n",
       "0   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.00  0.00  ...   \n",
       "1   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.00  0.00  ...   \n",
       "2   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.00  0.00  ...   \n",
       "3   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.00  0.00  ...   \n",
       "4   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.00  0.00  ...   \n",
       "\n",
       "   AS(NA)_5  AS(NA)_6  AS(NA)_7  AS(NAC)_0  AS(NAC)_1  AS(NAC)_2  AS(NAC)_3  \\\n",
       "0      0.00      0.00      0.00       0.00       0.00       0.00       0.00   \n",
       "1      0.00      0.00      0.00       0.00       0.00       0.00       0.00   \n",
       "2      0.00      0.00      0.00       0.00       0.00       0.00       0.00   \n",
       "3      0.00      0.00      0.00       0.00       0.00       0.00       0.00   \n",
       "4      0.00      0.00      0.00       0.00       0.00       0.00       0.00   \n",
       "\n",
       "   AS(NAC)_4  AS(NAC)_5  AS(NAC)_6  \n",
       "0       0.00       0.00       0.00  \n",
       "1       0.00       0.00       0.00  \n",
       "2       0.00       0.00       0.00  \n",
       "3       0.00       0.00       0.00  \n",
       "4       0.00       0.00       0.00  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 62 ms (started: 2022-12-26 03:35:10 +05:00)\n"
     ]
    }
   ],
   "source": [
    "hardware_classes = hardware_df[['AS(NAC)_7']]\n",
    "hardware_df.drop(columns = ['AS(NAC)_7'], inplace = True)  #Dropping unnecessary columns\n",
    "\n",
    "#Scaling and One-hot encoding\n",
    "Scaler = MinMaxScaler()\n",
    "hardware_df = pd.get_dummies(hardware_df)\n",
    "hardware_df = pd.DataFrame(Scaler.fit_transform(hardware_df), columns = hardware_df.columns)\n",
    "print('Shape of df now is: ', hardware_df.shape)\n",
    "hardware_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c12635",
   "metadata": {},
   "source": [
    "### 5.3.3 Dimensionality Reduction Techniques with ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacf230e",
   "metadata": {},
   "source": [
    "#### A) Dimensionaliy Reduction Pipeline for Regression Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b10bd4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 03:51:55 +05:00)\n"
     ]
    }
   ],
   "source": [
    "def dimensionality_reduction_regression(X_train, y_train, X_test, y_test, pca_dim = 0.95, ipca_dim= 0.95, svd_dim = 0.95):\n",
    "    \n",
    "    print(\"Starting DR Pipeline...\")\n",
    "\n",
    "    print(\"1. Running Lazy Predict without DR\")\n",
    "    \n",
    "#Running Lazy Predict without Dimensionality Reduction:\n",
    "    clf = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric = None)\n",
    "    simple_models = clf.fit(X_train, X_test, y_train, y_test)[0].sort_index()\n",
    "    simple_models['dim'] = X_train.shape[1]\n",
    "    simple_models.drop(columns = [ 'Time Taken'], inplace = True)\n",
    "    \n",
    "    print(\"Success!\")    \n",
    "\n",
    "#Model Performances with PCA:\n",
    "    \n",
    "    #Running PCA:\n",
    "    print(\"2. Running PCA\") \n",
    "    pca = PCA(n_components = pca_dim)\n",
    "    pca.fit(X_train)\n",
    "    X_train_transformed = pca.transform(X_train)\n",
    "    X_test_transformed = pca.transform(X_test)\n",
    "    print(\"Success!\")    \n",
    "    \n",
    "    #Running Lazy Predict with PCA\n",
    "    print(\"3. Running Lazy Predict on PCA dataset\") \n",
    "    clf = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric = None)\n",
    "    pcamodels = clf.fit(X_train_transformed, X_test_transformed, y_train, y_test)[0].sort_index()\n",
    "    pcamodels.drop(columns = [ 'Time Taken'], inplace = True)\n",
    "    pcamodels['dims'] = len(pca.components_)\n",
    "    print(\"Success!\")    \n",
    "\n",
    "    \n",
    "#Model Performances with Incremental-PCA:\n",
    "\n",
    "    #Running Incremental PCA:\n",
    "    print(\"4. Running Incremental PCA\") \n",
    "    for i in range(1, X_train.shape[1], 1):\n",
    "        ipca = IncrementalPCA(n_components = i)\n",
    "        ipca.fit(X_train)\n",
    "        X_train_transformed = ipca.transform(X_train)\n",
    "        X_test_transformed = ipca.transform(X_test)\n",
    "        \n",
    "        if ipca.explained_variance_ratio_.sum() >= ipca_dim:\n",
    "            print(\"Success!\")\n",
    "            print(\"5. Running Lazy Predict on Incremental PCA dataset\") \n",
    "            clf = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric = None)     #Running Lazy Predict after SVD\n",
    "            ipcamodels = clf.fit(X_train_transformed, X_test_transformed, y_train, y_test)[0].sort_index()\n",
    "            ipcamodels.drop(columns = [ 'Time Taken'], inplace = True)\n",
    "            ipcamodels['dims'] = ipca.n_components_\n",
    "            print(\"Success!\")\n",
    "            break\n",
    "    \n",
    "#Model Performances with Sparse-PCA:\n",
    "    print(\"6. Running Sparse PCA\")     \n",
    "    spca = SparsePCA(n_components = 10)\n",
    "    spca.fit(X_train)\n",
    "    X_train_transformed = spca.transform(X_train)\n",
    "    X_test_transformed = spca.transform(X_test)\n",
    "    print(\"Success!\")\n",
    "    \n",
    "    #Running Lazy Predict Sparse PCA:\n",
    "    print(\"7. Running Lazy Predict on Sparse PCA dataset\") \n",
    "    clf = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric = None)     #Running Lazy Predict after SVD\n",
    "    spcamodels = clf.fit(X_train_transformed, X_test_transformed, y_train, y_test)[0].sort_index()\n",
    "    spcamodels.drop(columns = [ 'Time Taken'], inplace = True)\n",
    "    spcamodels['dims'] = spca.n_components_    \n",
    "    print(\"Success!\")\n",
    "    \n",
    "    \n",
    "#Model Performances with SVD:\n",
    "\n",
    "    #Running SVD:\n",
    "    print(\"8. Running SVD\")        \n",
    "    for i in range(1, X_train.shape[1], 1):\n",
    "        svd = TruncatedSVD(n_components = i)\n",
    "        svd.fit(X_train)\n",
    "        X_train_transformed = svd.transform(X_train)\n",
    "        X_test_transformed = svd.transform(X_test)\n",
    "        \n",
    "        if svd.explained_variance_ratio_.sum() >= svd_dim or i>=X_train.shape[1]-1:\n",
    "            print(\"Success!\")\n",
    "            print(\"9. Running Lazy Predict on SVD dataset\")\n",
    "            clf = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric = None)     #Running Lazy Predict after SVD\n",
    "            svdmodels = clf.fit(X_train_transformed, X_test_transformed, y_train, y_test)[0].sort_index()\n",
    "            svdmodels.drop(columns = [ 'Time Taken'], inplace = True)\n",
    "            svdmodels['dims'] = len(svd.components_)\n",
    "            print(\"Success!\")\n",
    "            break\n",
    "\n",
    "\n",
    "    \n",
    "#Compiling Model Results:\n",
    "    print(\"Compiling Model Results\")\n",
    "    models_results = pd.concat([simple_models,\n",
    "                                pcamodels,\n",
    "                                ipcamodels,\n",
    "                                spcamodels,\n",
    "                                svdmodels], axis = 1, keys =['Without DR', 'PCA ', 'Incremental-PCA', 'Sparse-PCA', 'SVD'])\n",
    "    \n",
    "    print(\"Pipeline run Successful\")\n",
    "    \n",
    "    return models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a4bb2",
   "metadata": {},
   "source": [
    "#### B) Applying Pipeline to Regression Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4520566",
   "metadata": {},
   "source": [
    "#### 1. Power Consumption Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1e5c1393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 03:57:08 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(power_df, power_classes, test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1ad7cdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 42/42 [1:12:20<00:00, 103.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 42/42 [1:07:17<00:00, 96.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 42/42 [1:07:15<00:00, 96.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 42/42 [1:02:32<00:00, 89.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running SVD\n",
      "Success!\n",
      "9. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 42/42 [1:12:01<00:00, 102.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 5h 41min 27s (started: 2022-12-26 03:57:09 +05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_regression(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostRegressor', 'DecisionTreeRegressor',\n",
    "       'ElasticNetCV', 'GradientBoostingRegressor', 'KNeighborsRegressor', 'XGBRegressor',\n",
    "       'RandomForestRegressor', 'SVR']].T\n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Regression/Power_cons.xlsx', sheet_name = 'Power Consumption Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe07d3",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "964cbf79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dim</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.42</td>\n",
       "      <td>4</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5.91</td>\n",
       "      <td>3</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>6.14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.42</td>\n",
       "      <td>10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>6.09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>6.20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>6.23</td>\n",
       "      <td>3</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.36</td>\n",
       "      <td>10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5.99</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.70</td>\n",
       "      <td>10</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>5.55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.87</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.89</td>\n",
       "      <td>3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.03</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.71</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.71</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.84</td>\n",
       "      <td>10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.74</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.76</td>\n",
       "      <td>3</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.24</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.45</td>\n",
       "      <td>10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.24</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Without DR                     \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dim   \n",
       "Model                                                             \n",
       "AdaBoostRegressor                       0.90      0.90 5.42   4   \n",
       "DecisionTreeRegressor                   0.93      0.93 4.50   4   \n",
       "ElasticNetCV                            0.92      0.92 4.69   4   \n",
       "GradientBoostingRegressor               0.94      0.94 4.03   4   \n",
       "KNeighborsRegressor                     0.95      0.95 3.87   4   \n",
       "XGBRegressor                            0.96      0.96 3.24   4   \n",
       "RandomForestRegressor                   0.96      0.96 3.45   4   \n",
       "SVR                                     0.94      0.94 4.25   4   \n",
       "\n",
       "                                        PCA                       \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.88      0.88 5.91    3   \n",
       "DecisionTreeRegressor                   0.87      0.87 6.20    3   \n",
       "ElasticNetCV                            0.88      0.88 5.75    3   \n",
       "GradientBoostingRegressor               0.92      0.92 4.87    3   \n",
       "KNeighborsRegressor                     0.92      0.92 4.71    3   \n",
       "XGBRegressor                            0.92      0.92 4.74    3   \n",
       "RandomForestRegressor                   0.93      0.93 4.52    3   \n",
       "SVR                                     0.91      0.91 4.99    3   \n",
       "\n",
       "                             Incremental-PCA                      \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.87      0.87 6.14    3   \n",
       "DecisionTreeRegressor                   0.86      0.86 6.23    3   \n",
       "ElasticNetCV                            0.88      0.88 5.75    3   \n",
       "GradientBoostingRegressor               0.92      0.92 4.89    3   \n",
       "KNeighborsRegressor                     0.92      0.92 4.71    3   \n",
       "XGBRegressor                            0.92      0.92 4.76    3   \n",
       "RandomForestRegressor                   0.93      0.93 4.52    3   \n",
       "SVR                                     0.91      0.91 4.99    3   \n",
       "\n",
       "                                  Sparse-PCA                      \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.90      0.90 5.42   10   \n",
       "DecisionTreeRegressor                   0.93      0.93 4.36   10   \n",
       "ElasticNetCV                            0.92      0.92 4.70   10   \n",
       "GradientBoostingRegressor               0.94      0.94 4.03   10   \n",
       "KNeighborsRegressor                     0.95      0.95 3.84   10   \n",
       "XGBRegressor                            0.96      0.96 3.24   10   \n",
       "RandomForestRegressor                   0.96      0.96 3.45   10   \n",
       "SVR                                     0.94      0.94 4.24   10   \n",
       "\n",
       "                                         SVD                      \n",
       "                          Adjusted R-Squared R-Squared RMSE dims  \n",
       "Model                                                             \n",
       "AdaBoostRegressor                       0.87      0.87 6.09    3  \n",
       "DecisionTreeRegressor                   0.87      0.87 5.99    3  \n",
       "ElasticNetCV                            0.89      0.89 5.55    3  \n",
       "GradientBoostingRegressor               0.92      0.92 4.70    3  \n",
       "KNeighborsRegressor                     0.93      0.93 4.52    3  \n",
       "XGBRegressor                            0.92      0.92 4.77    3  \n",
       "RandomForestRegressor                   0.93      0.93 4.52    3  \n",
       "SVR                                     0.92      0.92 4.80    3  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-29 01:24:35 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Regression/Power_cons.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9ebb0",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ccd0c",
   "metadata": {},
   "source": [
    "For our analysis, I will be using adjusted R2 to make comparison since number of features are changing for each model:\n",
    "\n",
    "1. When no DR technique is applied, the best adjusted R2 score achieved was 0.96.\n",
    "2. After applying PCA, the R2 score slightly decreased to 0.93 with a reduction in features to 3 from 4.\n",
    "3. When applying other PCA variants, Incremental PCA behaved like PCA, but sparse PCA captured all the variance however it increased the dimensionality rather than decreasing it.\n",
    "4. When SVD was tried, the variance captured was 0.93 slightly less than 0.96 with 1 feature reduction so it performed at par with PCA.\n",
    "\n",
    "**Only 1 feature was reduced in these DR techniques with little compromise to variance capture, PCA and SVD performed at par with each other!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4902ae82",
   "metadata": {},
   "source": [
    "#### 2. Energy Efficiency Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0d116ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 09:38:36 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(energy_df, energy_classes, test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e71a58ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running SVD\n",
      "Success!\n",
      "9. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 15.4 s (started: 2022-12-26 09:38:36 +05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_regression(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostRegressor', 'DecisionTreeRegressor',\n",
    "       'ElasticNetCV', 'GradientBoostingRegressor', 'KNeighborsRegressor', 'XGBRegressor',\n",
    "       'RandomForestRegressor', 'SVR']].T\n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Regression/Energy.xlsx', sheet_name = 'Energy Efficiency Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce834233",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "be508569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dim</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.84</td>\n",
       "      <td>8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.23</td>\n",
       "      <td>5</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.66</td>\n",
       "      <td>10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.56</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.41</td>\n",
       "      <td>5</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.42</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.61</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2.68</td>\n",
       "      <td>8</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.88</td>\n",
       "      <td>5</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.88</td>\n",
       "      <td>5</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2.68</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.86</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.02</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.09</td>\n",
       "      <td>10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.57</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.72</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.03</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.76</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.78</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.34</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.51</td>\n",
       "      <td>8</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2.99</td>\n",
       "      <td>5</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2.99</td>\n",
       "      <td>5</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.53</td>\n",
       "      <td>10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Without DR                     \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dim   \n",
       "Model                                                             \n",
       "AdaBoostRegressor                       0.97      0.97 1.84   8   \n",
       "DecisionTreeRegressor                   1.00      1.00 0.47   8   \n",
       "ElasticNetCV                            0.93      0.93 2.68   8   \n",
       "GradientBoostingRegressor               1.00      1.00 0.45   8   \n",
       "KNeighborsRegressor                     0.96      0.96 2.01   8   \n",
       "XGBRegressor                            1.00      1.00 0.29   8   \n",
       "RandomForestRegressor                   1.00      1.00 0.44   8   \n",
       "SVR                                     0.94      0.94 2.51   8   \n",
       "\n",
       "                                        PCA                       \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.95      0.95 2.32    5   \n",
       "DecisionTreeRegressor                   0.98      0.98 1.41    5   \n",
       "ElasticNetCV                            0.92      0.92 2.88    5   \n",
       "GradientBoostingRegressor               0.99      0.99 0.96    5   \n",
       "KNeighborsRegressor                     0.94      0.94 2.50    5   \n",
       "XGBRegressor                            1.00      1.00 0.70    5   \n",
       "RandomForestRegressor                   0.99      0.99 0.76    5   \n",
       "SVR                                     0.91      0.91 2.99    5   \n",
       "\n",
       "                             Incremental-PCA                      \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.95      0.95 2.23    5   \n",
       "DecisionTreeRegressor                   0.98      0.98 1.42    5   \n",
       "ElasticNetCV                            0.92      0.92 2.88    5   \n",
       "GradientBoostingRegressor               0.99      0.99 0.93    5   \n",
       "KNeighborsRegressor                     0.94      0.94 2.50    5   \n",
       "XGBRegressor                            0.99      0.99 0.72    5   \n",
       "RandomForestRegressor                   0.99      0.99 0.78    5   \n",
       "SVR                                     0.91      0.91 2.99    5   \n",
       "\n",
       "                                  Sparse-PCA                      \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.97      0.97 1.66   10   \n",
       "DecisionTreeRegressor                   1.00      1.00 0.47   10   \n",
       "ElasticNetCV                            0.93      0.93 2.68   10   \n",
       "GradientBoostingRegressor               1.00      1.00 0.45   10   \n",
       "KNeighborsRegressor                     0.96      0.96 2.09   10   \n",
       "XGBRegressor                            1.00      1.00 0.30   10   \n",
       "RandomForestRegressor                   1.00      1.00 0.44   10   \n",
       "SVR                                     0.93      0.94 2.53   10   \n",
       "\n",
       "                                         SVD                      \n",
       "                          Adjusted R-Squared R-Squared RMSE dims  \n",
       "Model                                                             \n",
       "AdaBoostRegressor                       0.93      0.94 2.56    6  \n",
       "DecisionTreeRegressor                   0.97      0.97 1.61    6  \n",
       "ElasticNetCV                            0.92      0.92 2.86    6  \n",
       "GradientBoostingRegressor               0.99      0.99 1.02    6  \n",
       "KNeighborsRegressor                     0.93      0.94 2.57    6  \n",
       "XGBRegressor                            0.99      0.99 1.03    6  \n",
       "RandomForestRegressor                   0.98      0.98 1.34    6  \n",
       "SVR                                     0.90      0.90 3.13    6  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-29 01:24:58 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Regression/Energy.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34697b37",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2919a290",
   "metadata": {},
   "source": [
    "Adjusted R2 score is used to compare the results for the energy efficiency dataset:\n",
    "1. When no DR technique was applied, the best Adjusted R2 score achieved was 1 which means the model captures all the variance available.\n",
    "2. When PCA is applied, the features reduced to 5 from 8 but the best adjusted R2 score remained at 1 which shows PCA to be a good technique for this dataset.\n",
    "3. As other PCA variants are tried, incremental PCA performs at par with PCA, but Sparse PCA increases dimension, so it performs poorly.\n",
    "4. SVD reduced the dimensions dataset dimensions to 6 from 8 only with almost no compromise on variance capture.\n",
    "\n",
    "**PCA seems to perform well for this dataset as it reduces the maximum dimensions and maintains full variance of the dataset!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1bb56e",
   "metadata": {},
   "source": [
    "#### 3. Aquative Toxicity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "381123dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 15:57:25 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(aquatic_df, aquatic_classes, test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e299266b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 21.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 21.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running SVD\n",
      "Success!\n",
      "9. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 22.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 9.72 s (started: 2022-12-26 15:57:45 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_regression(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostRegressor', 'DecisionTreeRegressor',\n",
    "       'ElasticNetCV', 'GradientBoostingRegressor', 'KNeighborsRegressor', 'XGBRegressor',\n",
    "       'RandomForestRegressor', 'SVR']].T\n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Regression/aquatic.xlsx', sheet_name = 'Aquatic Toxicity Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f54d9",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "3e85568c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dim</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.22</td>\n",
       "      <td>7</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.32</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.61</td>\n",
       "      <td>5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.52</td>\n",
       "      <td>5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.32</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>1.67</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.19</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.19</td>\n",
       "      <td>5</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.17</td>\n",
       "      <td>7</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.19</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.17</td>\n",
       "      <td>10</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.22</td>\n",
       "      <td>7</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.19</td>\n",
       "      <td>5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.22</td>\n",
       "      <td>10</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.21</td>\n",
       "      <td>7</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.23</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Without DR                     \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dim   \n",
       "Model                                                             \n",
       "AdaBoostRegressor                       0.36      0.39 1.22   7   \n",
       "DecisionTreeRegressor                   0.26      0.30 1.32   7   \n",
       "ElasticNetCV                            0.39      0.42 1.20   7   \n",
       "GradientBoostingRegressor               0.42      0.45 1.17   7   \n",
       "KNeighborsRegressor                     0.36      0.40 1.22   7   \n",
       "XGBRegressor                            0.37      0.40 1.21   7   \n",
       "RandomForestRegressor                   0.42      0.45 1.16   7   \n",
       "SVR                                     0.42      0.45 1.16   7   \n",
       "\n",
       "                                        PCA                       \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.29      0.32 1.30    5   \n",
       "DecisionTreeRegressor                  -0.10     -0.06 1.61    5   \n",
       "ElasticNetCV                            0.40      0.42 1.19    5   \n",
       "GradientBoostingRegressor               0.34      0.37 1.25    5   \n",
       "KNeighborsRegressor                     0.41      0.43 1.18    5   \n",
       "XGBRegressor                            0.26      0.29 1.32    5   \n",
       "RandomForestRegressor                   0.42      0.44 1.17    5   \n",
       "SVR                                     0.41      0.43 1.18    5   \n",
       "\n",
       "                             Incremental-PCA                      \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.35      0.37 1.24    5   \n",
       "DecisionTreeRegressor                   0.03      0.06 1.52    5   \n",
       "ElasticNetCV                            0.40      0.42 1.19    5   \n",
       "GradientBoostingRegressor               0.40      0.42 1.19    5   \n",
       "KNeighborsRegressor                     0.40      0.43 1.19    5   \n",
       "XGBRegressor                            0.27      0.30 1.31    5   \n",
       "RandomForestRegressor                   0.43      0.45 1.16    5   \n",
       "SVR                                     0.41      0.43 1.18    5   \n",
       "\n",
       "                                  Sparse-PCA                      \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.44      0.48 1.13   10   \n",
       "DecisionTreeRegressor                   0.24      0.30 1.32   10   \n",
       "ElasticNetCV                            0.37      0.42 1.20   10   \n",
       "GradientBoostingRegressor               0.40      0.45 1.17   10   \n",
       "KNeighborsRegressor                     0.35      0.40 1.22   10   \n",
       "XGBRegressor                            0.36      0.41 1.21   10   \n",
       "RandomForestRegressor                   0.42      0.46 1.15   10   \n",
       "SVR                                     0.41      0.45 1.16   10   \n",
       "\n",
       "                                         SVD                      \n",
       "                          Adjusted R-Squared R-Squared RMSE dims  \n",
       "Model                                                             \n",
       "AdaBoostRegressor                       0.34      0.36 1.25    5  \n",
       "DecisionTreeRegressor                  -0.18     -0.13 1.67    5  \n",
       "ElasticNetCV                            0.40      0.42 1.19    5  \n",
       "GradientBoostingRegressor               0.42      0.44 1.17    5  \n",
       "KNeighborsRegressor                     0.42      0.44 1.17    5  \n",
       "XGBRegressor                            0.36      0.39 1.23    5  \n",
       "RandomForestRegressor                   0.47      0.49 1.12    5  \n",
       "SVR                                     0.45      0.47 1.14    5  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-29 01:25:25 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Regression/Aquatic.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa7606",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee21234a",
   "metadata": {},
   "source": [
    "For the aquatic toxicity dataset, adjusted R2 score is used. The models perform poorly which could be the issue with the dataset itself.\n",
    "1. The best adjusted R2 score achieved without any DR technique was 0.42.\n",
    "2. After applying PCA, the number of features reduced from 7 to 5 and adjusted R2 improved to 0.44.\n",
    "3. When other variants of PCA were tried, incremental PCA performed at par with PCA whereas sparse PCA increased dimensions instead.\n",
    "4. When SVD is applied, the performance improves further to 0.47 whereas the number of features reduces from 7 to 5. \n",
    "\n",
    "**SVD proves to perform better for this dataset while reducing the number of features and improving adjusted R2 score.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d946502",
   "metadata": {},
   "source": [
    "#### 4. Seoul Bikes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3d28b14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32 ms (started: 2022-12-26 10:24:12 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bikes_df, bikes_classes, test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5d5d3100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [44:09<00:00, 63.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [44:22<00:00, 63.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [43:55<00:00, 62.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [44:00<00:00, 62.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running SVD\n",
      "Success!\n",
      "9. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [47:39<00:00, 68.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 3h 44min 8s (started: 2022-12-26 10:24:12 +05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_regression(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostRegressor', 'DecisionTreeRegressor',\n",
    "       'ElasticNetCV', 'GradientBoostingRegressor', 'KNeighborsRegressor', 'XGBRegressor',\n",
    "       'RandomForestRegressor', 'SVR']].T\n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Regression/Bikes.xlsx', sheet_name = 'Seoul Bikes Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749ffa3",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "94b72b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dim</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>422.93</td>\n",
       "      <td>17</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>515.12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>503.04</td>\n",
       "      <td>8</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>481.62</td>\n",
       "      <td>10</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>493.99</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>325.76</td>\n",
       "      <td>17</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>415.19</td>\n",
       "      <td>8</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>411.11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>345.18</td>\n",
       "      <td>10</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>408.88</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>445.64</td>\n",
       "      <td>17</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>470.78</td>\n",
       "      <td>8</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>470.77</td>\n",
       "      <td>8</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>471.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>468.75</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>258.42</td>\n",
       "      <td>17</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>350.51</td>\n",
       "      <td>8</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>352.47</td>\n",
       "      <td>8</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>280.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>343.90</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>299.98</td>\n",
       "      <td>17</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>316.49</td>\n",
       "      <td>8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>316.98</td>\n",
       "      <td>8</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>338.48</td>\n",
       "      <td>10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>307.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>228.23</td>\n",
       "      <td>17</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>299.02</td>\n",
       "      <td>8</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>300.94</td>\n",
       "      <td>8</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>251.20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>299.15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>230.96</td>\n",
       "      <td>17</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>285.21</td>\n",
       "      <td>8</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>284.90</td>\n",
       "      <td>8</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>245.98</td>\n",
       "      <td>10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>285.19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>525.78</td>\n",
       "      <td>17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>544.90</td>\n",
       "      <td>8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>544.92</td>\n",
       "      <td>8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>544.78</td>\n",
       "      <td>10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>534.78</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Without DR                       \\\n",
       "                          Adjusted R-Squared R-Squared   RMSE dim   \n",
       "Model                                                               \n",
       "AdaBoostRegressor                       0.57      0.57 422.93  17   \n",
       "DecisionTreeRegressor                   0.74      0.75 325.76  17   \n",
       "ElasticNetCV                            0.52      0.53 445.64  17   \n",
       "GradientBoostingRegressor               0.84      0.84 258.42  17   \n",
       "KNeighborsRegressor                     0.78      0.78 299.98  17   \n",
       "XGBRegressor                            0.87      0.88 228.23  17   \n",
       "RandomForestRegressor                   0.87      0.87 230.96  17   \n",
       "SVR                                     0.33      0.34 525.78  17   \n",
       "\n",
       "                                        PCA                         \\\n",
       "                          Adjusted R-Squared R-Squared   RMSE dims   \n",
       "Model                                                                \n",
       "AdaBoostRegressor                       0.36      0.37 515.12    8   \n",
       "DecisionTreeRegressor                   0.59      0.59 415.19    8   \n",
       "ElasticNetCV                            0.47      0.47 470.78    8   \n",
       "GradientBoostingRegressor               0.71      0.71 350.51    8   \n",
       "KNeighborsRegressor                     0.76      0.76 316.49    8   \n",
       "XGBRegressor                            0.79      0.79 299.02    8   \n",
       "RandomForestRegressor                   0.80      0.81 285.21    8   \n",
       "SVR                                     0.29      0.29 544.90    8   \n",
       "\n",
       "                             Incremental-PCA                        \\\n",
       "                          Adjusted R-Squared R-Squared   RMSE dims   \n",
       "Model                                                                \n",
       "AdaBoostRegressor                       0.39      0.40 503.04    8   \n",
       "DecisionTreeRegressor                   0.59      0.60 411.11    8   \n",
       "ElasticNetCV                            0.47      0.47 470.77    8   \n",
       "GradientBoostingRegressor               0.70      0.70 352.47    8   \n",
       "KNeighborsRegressor                     0.76      0.76 316.98    8   \n",
       "XGBRegressor                            0.78      0.78 300.94    8   \n",
       "RandomForestRegressor                   0.81      0.81 284.90    8   \n",
       "SVR                                     0.29      0.29 544.92    8   \n",
       "\n",
       "                                  Sparse-PCA                        \\\n",
       "                          Adjusted R-Squared R-Squared   RMSE dims   \n",
       "Model                                                                \n",
       "AdaBoostRegressor                       0.44      0.45 481.62   10   \n",
       "DecisionTreeRegressor                   0.71      0.72 345.18   10   \n",
       "ElasticNetCV                            0.47      0.47 471.50   10   \n",
       "GradientBoostingRegressor               0.81      0.81 280.50   10   \n",
       "KNeighborsRegressor                     0.73      0.73 338.48   10   \n",
       "XGBRegressor                            0.85      0.85 251.20   10   \n",
       "RandomForestRegressor                   0.85      0.86 245.98   10   \n",
       "SVR                                     0.29      0.29 544.78   10   \n",
       "\n",
       "                                         SVD                        \n",
       "                          Adjusted R-Squared R-Squared   RMSE dims  \n",
       "Model                                                               \n",
       "AdaBoostRegressor                       0.41      0.42 493.99    9  \n",
       "DecisionTreeRegressor                   0.60      0.60 408.88    9  \n",
       "ElasticNetCV                            0.47      0.47 468.75    9  \n",
       "GradientBoostingRegressor               0.72      0.72 343.90    9  \n",
       "KNeighborsRegressor                     0.77      0.77 307.00    9  \n",
       "XGBRegressor                            0.79      0.79 299.15    9  \n",
       "RandomForestRegressor                   0.80      0.81 285.19    9  \n",
       "SVR                                     0.31      0.32 534.78    9  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-12-29 01:25:53 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Regression/Bikes.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce37c1",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aaa1e4",
   "metadata": {},
   "source": [
    "For the bikes sharing dataset, adjusted R2 score is used to compare the results:\n",
    "1. The best Adjusted R2 score was achieved to be 0.87 with 17 original features without any DR Technique.\n",
    "2. After applying PCA, the number of features reduced to 8 from 17 with some compromise on variance capture giving an R2 score of 0.81. \n",
    "3. For the PCA variants, incremental PCA performs like PCA and sparse PCA performs better as it reduces the number of features from 17 to 10 and still captures the same amount of variance giving an adjusted R2 score of 0.86.\n",
    "4. SVD performs at par with PCA however the number of dimensions is 1 more than PCA.\n",
    "\n",
    "**Sparse PCA performs well in this dataset as it reduces the number of features without any compromise on variance capture!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f72855",
   "metadata": {},
   "source": [
    "#### 5. Red Wine Quality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "396f9da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 14:08:20 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(redwine_df, redwine_classes, test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "5e5cbe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running SVD\n",
      "Success!\n",
      "9. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 41.2 s (started: 2022-12-26 14:08:20 +05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_regression(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostRegressor', 'DecisionTreeRegressor',\n",
    "       'ElasticNetCV', 'GradientBoostingRegressor', 'KNeighborsRegressor', 'XGBRegressor',\n",
    "       'RandomForestRegressor', 'SVR']].T\n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Regression/redwine.xlsx', sheet_name = 'Red Wine Quality Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5087d3",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "bf918930",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dim</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.79</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.81</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.82</td>\n",
       "      <td>10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.73</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.61</td>\n",
       "      <td>11</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.61</td>\n",
       "      <td>8</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.67</td>\n",
       "      <td>11</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.67</td>\n",
       "      <td>8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.66</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.61</td>\n",
       "      <td>11</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.61</td>\n",
       "      <td>10</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.61</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.57</td>\n",
       "      <td>11</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.61</td>\n",
       "      <td>11</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.61</td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Without DR                     \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dim   \n",
       "Model                                                             \n",
       "AdaBoostRegressor                       0.36      0.37 0.64  11   \n",
       "DecisionTreeRegressor                   0.01      0.04 0.79  11   \n",
       "ElasticNetCV                            0.36      0.37 0.64  11   \n",
       "GradientBoostingRegressor               0.41      0.43 0.61  11   \n",
       "KNeighborsRegressor                     0.30      0.32 0.67  11   \n",
       "XGBRegressor                            0.41      0.43 0.61  11   \n",
       "RandomForestRegressor                   0.47      0.49 0.57  11   \n",
       "SVR                                     0.40      0.42 0.61  11   \n",
       "\n",
       "                                        PCA                       \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.35      0.36 0.64    8   \n",
       "DecisionTreeRegressor                  -0.02      0.00 0.80    8   \n",
       "ElasticNetCV                            0.35      0.36 0.64    8   \n",
       "GradientBoostingRegressor               0.39      0.40 0.62    8   \n",
       "KNeighborsRegressor                     0.29      0.30 0.67    8   \n",
       "XGBRegressor                            0.36      0.37 0.64    8   \n",
       "RandomForestRegressor                   0.47      0.48 0.58    8   \n",
       "SVR                                     0.40      0.41 0.62    8   \n",
       "\n",
       "                             Incremental-PCA                      \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.34      0.35 0.65    8   \n",
       "DecisionTreeRegressor                  -0.04     -0.02 0.81    8   \n",
       "ElasticNetCV                            0.35      0.36 0.64    8   \n",
       "GradientBoostingRegressor               0.41      0.42 0.61    8   \n",
       "KNeighborsRegressor                     0.29      0.31 0.67    8   \n",
       "XGBRegressor                            0.40      0.41 0.62    8   \n",
       "RandomForestRegressor                   0.48      0.49 0.58    8   \n",
       "SVR                                     0.40      0.41 0.62    8   \n",
       "\n",
       "                                  Sparse-PCA                      \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.37      0.39 0.63   10   \n",
       "DecisionTreeRegressor                  -0.07     -0.04 0.82   10   \n",
       "ElasticNetCV                            0.36      0.37 0.64   10   \n",
       "GradientBoostingRegressor               0.42      0.44 0.60   10   \n",
       "KNeighborsRegressor                     0.32      0.34 0.66   10   \n",
       "XGBRegressor                            0.41      0.42 0.61   10   \n",
       "RandomForestRegressor                   0.47      0.49 0.58   10   \n",
       "SVR                                     0.40      0.42 0.61   10   \n",
       "\n",
       "                                         SVD                      \n",
       "                          Adjusted R-Squared R-Squared RMSE dims  \n",
       "Model                                                             \n",
       "AdaBoostRegressor                       0.36      0.37 0.64    8  \n",
       "DecisionTreeRegressor                   0.16      0.18 0.73    8  \n",
       "ElasticNetCV                            0.35      0.36 0.64    8  \n",
       "GradientBoostingRegressor               0.40      0.42 0.62    8  \n",
       "KNeighborsRegressor                     0.32      0.34 0.66    8  \n",
       "XGBRegressor                            0.41      0.42 0.61    8  \n",
       "RandomForestRegressor                   0.48      0.49 0.58    8  \n",
       "SVR                                     0.40      0.41 0.62    8  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-29 01:26:26 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Regression/redwine.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b27db7",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e346f",
   "metadata": {},
   "source": [
    "For the Red wine quality dataset, adjusted R2 score is used to compare the results:\n",
    "\n",
    "1. The best Adjusted R2 score was achieved to be 0.47 with 11 original features without any DR Technique.\n",
    "2. After applying PCA, the number of features reduced to 8 from 11 with no difference in R2 score proving it to be a particularly good DR technique for this dataset\n",
    "3. For the PCA variants, both incremental and sparse performed at par with PCA\n",
    "4. SVD performs reduces number of features to 8 from 11 which is at par with PCA however the adjusted R2 slightly improves but 0.01 difference is not generalizable.\n",
    "\n",
    "\n",
    "**PCA, its variants and SVD all perform well for this dataset!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e00ce97",
   "metadata": {},
   "source": [
    "#### 6. Student Portugese Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "118872ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-26 16:15:29 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(student_df, student_classes, test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "9ff0a287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running SVD\n",
      "Success!\n",
      "9. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 15.5 s (started: 2022-12-26 16:15:30 +05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_regression(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostRegressor', 'DecisionTreeRegressor',\n",
    "       'ElasticNetCV', 'GradientBoostingRegressor', 'KNeighborsRegressor', 'XGBRegressor',\n",
    "       'RandomForestRegressor', 'SVR']].T\n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Regression/Student.xlsx', sheet_name = \"Student Portugese Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9543c7be",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "6c141adf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dim</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.47</td>\n",
       "      <td>58</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.91</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.24</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.04</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.93</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>4.32</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>4.06</td>\n",
       "      <td>29</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>4.98</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>3.74</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.36</td>\n",
       "      <td>58</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.83</td>\n",
       "      <td>29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.83</td>\n",
       "      <td>29</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.74</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.46</td>\n",
       "      <td>58</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.92</td>\n",
       "      <td>29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.93</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>3.39</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.94</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.38</td>\n",
       "      <td>58</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.95</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.05</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>3.34</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.98</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.57</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>29</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.95</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>3.66</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.04</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.43</td>\n",
       "      <td>58</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.83</td>\n",
       "      <td>29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.86</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.17</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.89</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.87</td>\n",
       "      <td>58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.82</td>\n",
       "      <td>29</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.85</td>\n",
       "      <td>29</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.14</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.81</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Without DR                     \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dim   \n",
       "Model                                                             \n",
       "AdaBoostRegressor                       0.69      0.80 1.47  58   \n",
       "DecisionTreeRegressor                   0.46      0.65 1.93  58   \n",
       "ElasticNetCV                            0.73      0.83 1.36  58   \n",
       "GradientBoostingRegressor               0.69      0.80 1.46  58   \n",
       "KNeighborsRegressor                     0.18      0.47 2.38  58   \n",
       "XGBRegressor                            0.64      0.77 1.57  58   \n",
       "RandomForestRegressor                   0.70      0.81 1.43  58   \n",
       "SVR                                     0.49      0.67 1.87  58   \n",
       "\n",
       "                                        PCA                       \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                       0.04      0.21 2.91   29   \n",
       "DecisionTreeRegressor                  -1.12     -0.74 4.32   29   \n",
       "ElasticNetCV                            0.09      0.25 2.83   29   \n",
       "GradientBoostingRegressor               0.03      0.21 2.92   29   \n",
       "KNeighborsRegressor                     0.01      0.19 2.95   29   \n",
       "XGBRegressor                           -0.02      0.16 3.00   29   \n",
       "RandomForestRegressor                   0.09      0.25 2.83   29   \n",
       "SVR                                     0.10      0.26 2.82   29   \n",
       "\n",
       "                             Incremental-PCA                      \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                      -0.02      0.16 3.00   29   \n",
       "DecisionTreeRegressor                  -0.87     -0.54 4.06   29   \n",
       "ElasticNetCV                            0.09      0.25 2.83   29   \n",
       "GradientBoostingRegressor               0.03      0.20 2.93   29   \n",
       "KNeighborsRegressor                    -0.06      0.13 3.05   29   \n",
       "XGBRegressor                            0.01      0.19 2.95   29   \n",
       "RandomForestRegressor                   0.07      0.24 2.86   29   \n",
       "SVR                                     0.08      0.24 2.85   29   \n",
       "\n",
       "                                  Sparse-PCA                      \\\n",
       "                          Adjusted R-Squared R-Squared RMSE dims   \n",
       "Model                                                              \n",
       "AdaBoostRegressor                      -0.04      0.02 3.24   10   \n",
       "DecisionTreeRegressor                  -1.46     -1.31 4.98   10   \n",
       "ElasticNetCV                            0.08      0.14 3.04   10   \n",
       "GradientBoostingRegressor              -0.14     -0.07 3.39   10   \n",
       "KNeighborsRegressor                    -0.11     -0.04 3.34   10   \n",
       "XGBRegressor                           -0.33     -0.25 3.66   10   \n",
       "RandomForestRegressor                   0.00      0.06 3.17   10   \n",
       "SVR                                     0.02      0.08 3.14   10   \n",
       "\n",
       "                                         SVD                      \n",
       "                          Adjusted R-Squared R-Squared RMSE dims  \n",
       "Model                                                             \n",
       "AdaBoostRegressor                      -0.05      0.14 3.04   29  \n",
       "DecisionTreeRegressor                  -0.59     -0.30 3.74   29  \n",
       "ElasticNetCV                            0.14      0.30 2.74   29  \n",
       "GradientBoostingRegressor               0.02      0.20 2.94   29  \n",
       "KNeighborsRegressor                    -0.01      0.17 2.98   29  \n",
       "XGBRegressor                           -0.05      0.14 3.04   29  \n",
       "RandomForestRegressor                   0.05      0.22 2.89   29  \n",
       "SVR                                     0.10      0.27 2.81   29  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-29 01:26:53 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Regression/Student.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c2398",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d894f06",
   "metadata": {},
   "source": [
    "Adjusted R2 score is used to compare the results for the student performance dataset:\n",
    "\n",
    "1. When no DR technique was applied, the best Adjusted R2 score achieved was 0.70.\n",
    "2. When PCA is applied, the features reduced from 58 to 29 but the best the adjusted R2 score drops significantly which means PCA is not a good DR technique for this dataset.\n",
    "3. The rest of the PCA variants and SVD performs poorly as well!\n",
    "**This dataset does not seem to allow any feature reduction which could be highlighting that there is a remarkably high correlation between some variables with predicted value!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705d40d0",
   "metadata": {},
   "source": [
    "#### 7. Tom's Hardware Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3296e047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 94 ms (started: 2022-12-26 14:09:39 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#lets split the data into a train test split from the start, test set will be kept separate and will only be used for testing purposes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(hardware_df, hardware_classes, test_size=0.25, random_state =43)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "2bf6a5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DR Pipeline...\n",
      "1. Running Lazy Predict without DR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [13:19<00:00, 19.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "2. Running PCA\n",
      "Success!\n",
      "3. Running Lazy Predict on PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [10:54<00:00, 15.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "4. Running Incremental PCA\n",
      "Success!\n",
      "5. Running Lazy Predict on Incremental PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [11:01<00:00, 15.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "6. Running Sparse PCA\n",
      "Success!\n",
      "7. Running Lazy Predict on Sparse PCA dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [10:26<00:00, 14.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "8. Running SVD\n",
      "Success!\n",
      "9. Running Lazy Predict on SVD dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [10:52<00:00, 15.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Compiling Model Results\n",
      "Pipeline run Successful\n",
      "time: 56min 41s (started: 2022-12-26 14:09:39 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Pipeline run\n",
    "models_results = dimensionality_reduction_regression(X_train, y_train, X_test, y_test, pca_dim = 0.95, svd_dim = 0.95)\n",
    "\n",
    "#keeping only the desired algorithms\n",
    "results = models_results.T[['AdaBoostRegressor', 'DecisionTreeRegressor',\n",
    "       'ElasticNetCV', 'GradientBoostingRegressor', 'KNeighborsRegressor', 'XGBRegressor',\n",
    "       'RandomForestRegressor', 'SVR']].T\n",
    "\n",
    "#Exporting results to excel\n",
    "results.to_excel('Results/Regression/hardware.xlsx', sheet_name = \"Tom's Hardware Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc938f82",
   "metadata": {},
   "source": [
    "##### Dataset Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "bf416907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without DR</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Incremental-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sparse-PCA</th>\n",
       "      <th colspan=\"4\" halign=\"left\">SVD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dim</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>dims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4458.21</td>\n",
       "      <td>96</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>21948.76</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>21005.85</td>\n",
       "      <td>18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>12182.41</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>22217.19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>96</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5893.47</td>\n",
       "      <td>18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>5523.79</td>\n",
       "      <td>18</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>6623.64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>6240.60</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5304.48</td>\n",
       "      <td>96</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11946.31</td>\n",
       "      <td>18</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11946.38</td>\n",
       "      <td>18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>11885.54</td>\n",
       "      <td>10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11898.39</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2354.97</td>\n",
       "      <td>96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4118.33</td>\n",
       "      <td>18</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4021.61</td>\n",
       "      <td>18</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4589.20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4176.74</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3006.69</td>\n",
       "      <td>96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4498.94</td>\n",
       "      <td>18</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4495.64</td>\n",
       "      <td>18</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>4755.76</td>\n",
       "      <td>10</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4505.91</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2290.19</td>\n",
       "      <td>96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4063.83</td>\n",
       "      <td>18</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4057.10</td>\n",
       "      <td>18</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4924.35</td>\n",
       "      <td>10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4150.92</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2297.70</td>\n",
       "      <td>96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4143.08</td>\n",
       "      <td>18</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4199.52</td>\n",
       "      <td>18</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>4699.13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4099.51</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>13124.97</td>\n",
       "      <td>96</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>13216.94</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>13216.98</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>13121.29</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>13209.49</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Without DR                         \\\n",
       "                          Adjusted R-Squared R-Squared     RMSE dim   \n",
       "Model                                                                 \n",
       "AdaBoostRegressor                       0.88      0.88  4458.21  96   \n",
       "DecisionTreeRegressor                   0.92      0.92  3697.34  96   \n",
       "ElasticNetCV                            0.83      0.83  5304.48  96   \n",
       "GradientBoostingRegressor               0.97      0.97  2354.97  96   \n",
       "KNeighborsRegressor                     0.95      0.95  3006.69  96   \n",
       "XGBRegressor                            0.97      0.97  2290.19  96   \n",
       "RandomForestRegressor                   0.97      0.97  2297.70  96   \n",
       "SVR                                    -0.03     -0.02 13124.97  96   \n",
       "\n",
       "                                        PCA                           \\\n",
       "                          Adjusted R-Squared R-Squared     RMSE dims   \n",
       "Model                                                                  \n",
       "AdaBoostRegressor                      -1.85     -1.85 21948.76   18   \n",
       "DecisionTreeRegressor                   0.79      0.79  5893.47   18   \n",
       "ElasticNetCV                            0.15      0.16 11946.31   18   \n",
       "GradientBoostingRegressor               0.90      0.90  4118.33   18   \n",
       "KNeighborsRegressor                     0.88      0.88  4498.94   18   \n",
       "XGBRegressor                            0.90      0.90  4063.83   18   \n",
       "RandomForestRegressor                   0.90      0.90  4143.08   18   \n",
       "SVR                                    -0.03     -0.03 13216.94   18   \n",
       "\n",
       "                             Incremental-PCA                          \\\n",
       "                          Adjusted R-Squared R-Squared     RMSE dims   \n",
       "Model                                                                  \n",
       "AdaBoostRegressor                      -1.61     -1.61 21005.85   18   \n",
       "DecisionTreeRegressor                   0.82      0.82  5523.79   18   \n",
       "ElasticNetCV                            0.15      0.16 11946.38   18   \n",
       "GradientBoostingRegressor               0.90      0.90  4021.61   18   \n",
       "KNeighborsRegressor                     0.88      0.88  4495.64   18   \n",
       "XGBRegressor                            0.90      0.90  4057.10   18   \n",
       "RandomForestRegressor                   0.90      0.90  4199.52   18   \n",
       "SVR                                    -0.03     -0.03 13216.98   18   \n",
       "\n",
       "                                  Sparse-PCA                          \\\n",
       "                          Adjusted R-Squared R-Squared     RMSE dims   \n",
       "Model                                                                  \n",
       "AdaBoostRegressor                       0.12      0.12 12182.41   10   \n",
       "DecisionTreeRegressor                   0.74      0.74  6623.64   10   \n",
       "ElasticNetCV                            0.16      0.17 11885.54   10   \n",
       "GradientBoostingRegressor               0.88      0.88  4589.20   10   \n",
       "KNeighborsRegressor                     0.87      0.87  4755.76   10   \n",
       "XGBRegressor                            0.86      0.86  4924.35   10   \n",
       "RandomForestRegressor                   0.87      0.87  4699.13   10   \n",
       "SVR                                    -0.02     -0.02 13121.29   10   \n",
       "\n",
       "                                         SVD                          \n",
       "                          Adjusted R-Squared R-Squared     RMSE dims  \n",
       "Model                                                                 \n",
       "AdaBoostRegressor                      -1.92     -1.92 22217.19   18  \n",
       "DecisionTreeRegressor                   0.77      0.77  6240.60   18  \n",
       "ElasticNetCV                            0.16      0.16 11898.39   18  \n",
       "GradientBoostingRegressor               0.90      0.90  4176.74   18  \n",
       "KNeighborsRegressor                     0.88      0.88  4505.91   18  \n",
       "XGBRegressor                            0.90      0.90  4150.92   18  \n",
       "RandomForestRegressor                   0.90      0.90  4099.51   18  \n",
       "SVR                                    -0.03     -0.03 13209.49   18  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-12-29 01:27:20 +05:00)\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "results = pd.read_excel('Results/Regression/hardware.xlsx', header=[0, 1], index_col=0 )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2eb3da",
   "metadata": {},
   "source": [
    "##### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28894fb9",
   "metadata": {},
   "source": [
    "Adjusted R2 score is used to compare the results for the Tom's Hardware dataset:\n",
    "\n",
    "1. When no DR technique was applied, the best Adjusted R2 score achieved was 0.97 which means the model captures almost all  the variance available.\n",
    "2. When PCA is applied, the features reduced from 96 to 18 but with a small drop in adjusted R2 score of 0.06 which leads to an R2 score of 0.90.\n",
    "3. As other PCA variants are tried, incremental PCA performs at par with PCA but sparse reduces dimensions to 10 with some more compromise on adjusted R2 value leading to R2 score of 0.87\n",
    "4. SVD performs at par with PCA as it leads to an adjusted R2 score of 0.9 and gives a feature set of 18 dimensions.\n",
    "\n",
    "**PCA and SVD both perform well as they reduce the number of features from 96 to 18 and capture all variance!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95414fa",
   "metadata": {},
   "source": [
    "# 6. Critical Analysis\n",
    "\n",
    "All the datasets do not compromise a lot on variance capture when their dimensionality is reduced using any of the techniques tried above which proves that these techniques are especially useful and should be implemented before diving deep into machine learning. Spending some time on reducing dimensions would help in the long run since model development becomes easier and less time-consuming when dataset features are reduced. Furthermore, LDA is only applicable on classification datasets and there are other varying factors which does not allow generalizability amongst all datasets however, it can be concurred that PCA works well for all datasets as it helps reduce dimensions more significantly and does not compromise a lot on variance capture which is the major goal of PCA itself. The major reason that these techniques work so well is because tabular data can be explained via linear mappings. Since PCA, LDA and SVD all are linear transformers, they can capture the hidden trends in the data well. However, same cannot be said for textual or image data where there are non-linear patterns.\n",
    "\n",
    "### 6.1 Classification Datasets\n",
    "\n",
    "\n",
    "Most of the techniques performed well but Linear discriminant analysis stood out for every dataset. LDA significantly reduced dimensions without compromising on variance capture making it an extremely useful technique. The major reason LDA can outperform the other techniques is because it is a supervised one which could be considered its drawback as well. However, since we are focused on classification, we would require a labeled dataset and LDA uses the labels along with the dataset to increase separability between classes. PCA only focuses on the linear mappings between the predictor variable whereas LDA focuses on linear mapping between the entire dataset and predicted variable as well. In addition, LDA's focus on class separability becomes the major factor that helps in improving classification since LDA focuses on capturing distinct information between the classes. However, LDA forcefully reduces dimensions to less than number of classes which may cause losing essential information if the entire dataset is relevant so we must resort to PCA or SVD if there is a major performance drop with LDA.\n",
    "\n",
    "\n",
    "### 6.2 Regression Datasets\n",
    "For regression datasets, LDA was not applicable as it requires a classification dataset. PCA worked well for these as it was able to capture most of the variance with significant feature reduction. Singular value decomposition performed like PCA as well where in some cases it was able to surpass PCA however PCA still remained the winner technique for regression datasets. The reason PCA works so well is because it can remove multicollinearity between variables and map the dataset on independent dimensions that capture the highest variance. Furthermore, because regression has a continuous output, it is more prone to having noise than classification datasets so amongst the other techniques PCA can handle noise better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda1d97",
   "metadata": {},
   "source": [
    "# 7. Conclusion\n",
    "\n",
    "Overall, DR techniques must become a standard pre-processing step for high dimensional datasets to avoid unnecessary prolonged computation time and make machine learning simpler."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
